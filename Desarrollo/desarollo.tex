\chapter{Desarrollo.}
\section{Instalación del servidor PowerTAC y conexión con el broker Sample}

Como parte de la actividad de estudio de la plataforma PowerTAC, fue necesario familiarizarse con el servidor, aprender su configuración básica, y la configuración necesaria para conectarse a uno o varios brokers para hacer que compitan, a su vez, familiarizarse con el ambiente de desarrollo de un broker y su configuración para conectarse a un servidor. A continuación se muestra un resumen de la investigación que se hizo sobre la plataforma.
%no se si sea necesario
\subsection{Power TAC}

Power TAC es una competencia anual que se ha realizado desde 2012, donde se simulan futuros mercados minoristas liberados de energía eléctrica, en la que los competidores son entidades de negocios o ``Brokers'' (En la simulación son agentes Inteligentes) minoristas que compran y venden energía tanto en los mercados al por mayor como al por menor.

Los brokers ofrecen servicios de energía a los clientes a través de contratos tarifarios, y luego deben servir a esos clientes negociando esa energía en el mercado al por mayor. En la competencia los brokers son desafiados a maximizar sus ganancias comprando y vendiendo energía en los mercados mayorista y minorista, sujetos a costos fijos y restricciones, el ganador de un juego o simulación individual es el broker con el saldo bancario más alto al final de la simulación \cite{WKetterJCollinsyMdWeerdtThe2017PowerTAC}.

El mercado minorista está integrado por consumidores y productores pequeños, tales como hogares, pequeñas y medianas empresas, propietarios de vehículos eléctricos, etc. es un mercado de tarifas, en el que los clientes pueden elegir entre ofertas de contratos tarifarios de los brokers competidores, comprando pequeñas cantidades de energía (pequeñas en contraste con el mercado al por mayor).

En el mercado al por mayor los brokers interactúan entre si directamente así como con grandes compañías productoras y otros participantes del mercado al por mayor vendiendo y comprando grandes cantidades de energía, la cual usan para venderla en el mercado al por menor. Los clientes son modelos de usuarios domésticos, empresariales e institucionales de energía eléctrica, así como productores de energía que poseen paneles solares o turbinas eólicas.

\subsection{Servidor}

Debido a que se trata de un proyecto de Maven, lo primero que se hizo fue instalarlo, para esto se descargó de su página oficial el paquete de instalación en un archivo zip: \textsf{http://maven.apache.org/download.cgi}
Para instalarlo, basta con descomprimirlo en la carpeta deseada, en este caso el directorio de instalación elegido fue:\\ \texttt{/usr/local/apache-maven-3.3.9}, 
para usarlo en la terminal, fue necesario agregar la carpeta de instalación: \texttt{/usr/local/apache-maven-3.3.9/bin} 
a la variable de entorno path del sistema.

Para esto se agregó la dirección de la carpeta de instalación a los archivos:\\
\texttt{/etc/environment y /etc/profile}, para resultados inmediatos se usó el comando:\\
\texttt{export PATH=\$PATH:/usr/local/apache-maven-3.3.9/bin}\\

Una vez instalado el software Maven, el siguiente paso fue descargar el archivo zip del proyecto de este enlace:\\ \textsf{https://github.com/powertac/server-distribution/releases/tag/v1.3.2}\\
Al terminar la descarga se descomprimió el archivo zip en la carpeta de trabajo\\
\texttt{/home/Documentos/power tac/} \\
Para ejecutar el servidor nos movemos al directorio raíz del proyecto y escribimos el comando correspondiente al modo que queremos ejecutar, el simulador dispone de tres modos: el modo bootstrap, el modo simulación y el modo web.

\begin{enumerate}
	\item \textbf{Bootstrap:} Es necesario correr este modo previamente a la simulación, en este modo se genera un archivo de datos bootstrap, el cual sirve como datos preliminares para ejecutar el modo simulación, este archivo contiene información del clima, información del mercado de tarifas entre otras cosas.

	\item \textbf{Simulación:} Inicia la simulación de entorno donde varios brokers se conectan al servidor y compiten entre sí.
	\item \textbf{Web: } Despliega un servidor web por el cual se puede arrancar cualquiera de los dos modos del servidor anteriores usando una interfaz gráfica amigable, además en el modo simulación dispone de una herramienta de visualización.
\end{enumerate}

Para correr el simulador en modo bootstrap se usó el siguiente comando:\\
\texttt{mvn -Pcli -Dexec.args=``--boot bootstrap-data ''}\\
Donde \texttt{bootstrap-data} es el nombre que se le pondrá al archive generado.
Para correr el servidor en modo simulación se usó el siguiente comando:\\
\texttt{mvn -Pcli -Dexec.args=``--sim --boot-data bootstrap-data ''}

Una vez más \texttt{bootstrap-data} es el nombre del archivo generado por el modo bootstrap. Hay más parámetros para correr el servidor y estos se toman por default del archivo server.properties el cual contiene la configuración por defecto, algunos de estos parámetros de configuración aparecen en la tabla que aparece en la figura \ref{tab:parametros}.

Por último el comando para desplegar el servidor web es el siguiente:
\texttt{mvn -P web}

Al entrar en la interfaz web del servidor podemos ver que nos muestra un formulario para iniciar cualquiera de los modos anteriores (bootstrap o simulación), este formulario se muestra en la figura \ref{fig:interfazFormularioWeb}.

Para correr el modo simulación desde la interfaz web se pusieron los parámetros de la \ref{tab:parametros}.

\begin{table}[!h]
	\begin{center}
		\begin{tabular}{|p{2.5cm}|p{7cm}|p{4cm}|}\hline
			\textbf{Parámetro} & \textbf{Descripción} & \textbf{Valor} \\ \hline
				Input Bootstrap data:  &El nombre del archivo xml generado en el modo bootstrap. & \texttt{bootstrap-data} \\ \hline
				JMS URL: & La url del JMS del broker, este es el valor default. & \texttt{tcp://localhost:61616} \\\hline
				Brokers  & El nombre de usuario del o los brokers que el servidor esperara a que se conecten. & \texttt{Sample}
			\\ \hline
		\end{tabular}			
	\end{center}
	\caption{ Parámetros del servidor.}
	\label{tab:parametros}
\end{table}

%imagen 

\begin{figure}[!h]
	\centering
	\includegraphics[width=13cm]{img/interfazFormularioWeb.png}
	\caption{Interfaz web del servidor powerTAC}
	\label{fig:interfazFormularioWeb}
\end{figure}

Los otros parámetros (Server-config, Log suffix, Seed file, Weather file) se dejaron en blanco y toman valores por defecto, para propósitos de esta prueba no son necesarios.

Una vez listos los parámetros se inició la sesión dando click en el boton Run Sim, justo abajo del formulario de los parámetros, esto inicia el simulador pero no empieza la simulación %(muestra el mensaje “simulation started”) 
(muestra el mensaje ``simulation started'') 
es decir, no inicio el juego, ya que el servidor quedo en espera del broker Sample.

\subsection{Broker}
Debido a que el broker es en lo que se trabajará agregando funcionalidades, se decidió usar un IDE para tener un buen ambiente de desarrollo, y no solo manejarlo desde la consola como se hizo con el servidor. El IDE elegido para esta prueba fue NetBeans.
Para descargar el broker de ejemplo se usó la herramienta integrada en NetBeans para descargar directamente del repositorio GitHub usando este enlace: \textsf{https://github.com/powertac/sample-broker}\\
En la figura \ref{fig:asistenteNetbeansClonar} se muestra la ventana del asistente de NetBeans para clonar repositorios desde un servidor git.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{img/asistenteNetbeansClonar.png}
	\caption{Asistente de NetBeans para clonar proyectos desde un servidor git.}
	\label{fig:asistenteNetbeansClonar}
\end{figure}

Los parámetros de configuración del broker pueden ponerse en los argumentos a la hora de ejecutarlo desde consola, si estos se omiten, el broker los lee por defecto del archivo broker.properties lo cual resulta útil porque solo hace falta correr el proyecto sin ningún parámetro adicional, haciendo posible ejecutarlo desde NetBeans sin modificar los argumentos de ejecución.

En el archivo broker.properties se encuentran varias propiedades, de ellas son de especial importancia las siguientes:\\

\lstset{language=Xml, label=lst:parametrosBroker, caption={[Archivo \texttt{broker.properties}] Archivo \texttt{broker.properties}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
# - - - - - - - username, password - - - - - - -
samplebroker.core.powerTacBroker.username = Sample
samplebroker.core.powerTacBroker.password = secret
# - - - - - - - - - - - JMS - - - - - - - - - - -
samplebroker.core.jmsManagementService.jmsBrokerUrl =
tcp://localhost:61616
\end{lstlisting}

El valor de la propiedad \texttt{username} de la línea 101 
tiene que coincidir con el parámetro Brokers que se le pasa al servidor al iniciar la simulación, así como también el valor del parámetro \texttt{jmsBrokerUrl} de la línea 104 tiene que coincidir con el parámetro JMS URL de la configuración inicial de la simulación del servidor.\\

Una vez asegurado que los parámetros del broker y el servidor coincidan, se procede a ejecutar el broker, para esto solo damos clic derecho al proyecto y seleccionamos la opción run; 
Si no está seleccionada una clase Main por defecto (que contenga el método main), nos aparecerá una ventana para que seleccionemos la clase a ejecutar, esta es:\\ \texttt{org.powertac.samplebroker.core.BrokerMain}.

Al hacer esto NetBeans se encargara de construir y corre el proyecto usando Maven, al ser NetBeans quien lo ejecuta, no usa ningún parámetro extra en la ejecución por lo que todas las propiedades las lee del archivo \texttt{broker.properties}.

También es posible correr el broker desde la consola del sistema, Para correr el broker desde la consola, es necesario posicionarse en el directorio raiz del proyecto, en este caso es \texttt{/root/NetBeansProjects/sample-broker\#} y simplemente ejecutar el comando:\\
\texttt{mvn compile exec:exec -Dexec.args="--config \\
broker.properties"\\
}

Donde \texttt{broker.properties} es el archivo de configuración que contiene las propiedades del broker (Como el nombre y su JMS URL).
Esto iniciara la descarga de las dependencias necesarias (si aún no se tienen), la construcción del proyecto y la ejecución del broker con los parámetros especificados en el archivo \texttt{broker.properties}, si se desea especificar otro archivo de propiedades es necesario hacerlo en el comando.

\subsection{Servidor en marcha}
La versión web del servidor dispone de una herramienta de visualización web, la cual muestra los resultados de la prueba en tiempo real, después de varios minutos de correr la simulación, la ventana de resultados se parece a la que se muestra en la figura \ref{fig:visualizadorWebResultados}.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{img/visualizadorWebResultados.png}
	\caption{Visualizador web de resultados de la simulación.}
	\label{fig:visualizadorWebResultados}
\end{figure}

En la figura \ref{fig:visualizadorWebResultados} el eje $x$ representa el tiempo y el eje $y$ representa la ganancia del broker correspondiente, podemos ver como el Sample broker (el broker que se ejecutó desde NetBeans) inicio con menos ganancias pero conforme
transcurrió el tiempo le gano por mucho al default broker (el broker por defecto que tiene el simulador el cual no ejecuta ninguna estrategia), de igual manera, si hubiera más brokers conectados al servidor estos aparecerían en el gráfico.

Estos resultados de la simulación se guardan además en la carpeta log, que está en la raíz del proyecto, en los archivos \texttt{powertac-sim-0.state} y \texttt{powertac-sim-0.trace}, y cada vez que se corre una simulación el número que en esta primera prueba fue 0, va aumentando.

\section{Estudio de métodos de regresión}
El objetivo es este proyecto es mejorar el broker del INAOE COLDPower, implementando nuevas técnicas que permitan predecir mejor el clima y los patrones de consumo de energía de la población para tomar mejores decisiones y mejorar el rendimiento del broker (aumentar las ganancias en las simulaciones); para llegar a esto fue necesario primero estudiar diversas técnicas de predicción como parte del desarrollo del proyecto, empezando por análisis de regresión. En esta parte del proyecto se llego al siguiente resumen.

Dentro del análisis de regresión hay dos modelos simples por los cuales se
empezó: La regresión lineal y polinomial.

\subsection{Regresión lineal}
El análisis de regresión lineal nos puede ayudar a conocer 3 cosas:

\begin{enumerate}
	\item Si las variables independientes están relacionadas con la variable dependiente, o ayudan a explicar los cambios en la variable dependiente.
	\item Determinar que variables en particular son predictores significativos de la variable dependiente y de qué manera la afectan, la manera en que una variable $x_i$ afecta a la variable dependiente está dada por su coeficiente $\beta_i$ en el modelo generado.
	\item Generar un modelo que muestre como el conjunto de variables predictoras o independientes, pueden ser usadas para predecir valores desconocidos de la variable dependiente y así poder hacer pronósticos. Este modelo naturalmente esta expresado en una ecuación, la cual es una combinación lineal del conjunto de variables independientes.
\end{enumerate}

El estudio de esta técnica fue útil para entender los métodos de regresión en general, ya que es la forma más simple y algunas otras técnicas son parecidas a esta o incluso se basan en ella, como la regresión polinomial, y esta fue el primer tipo de análisis de regresión en estudiarse rigurosamente y en ser usado extensamente en aplicaciones prácticas \cite{XYanLinearRegressionAnalysis}.
Esto es porque los modelos que dependen linealmente de sus variables son más fáciles de ajustar que modelos que son no lineales en cuanto a la relación de sus parámetros y porque las propiedades estadísticas de los estimadores resultantes son más fáciles de determinar.

\subsection{Regresión polinomial}\label{subsec:regresionPolinomial}
Como extensión al algoritmo de regresión lineal, se estudió también el análisis de regresión polinomial y su relación con la regresión lineal, que aunque sirve para describir un modelo donde las variables son no lineales (un polinomio), los parámetros a encontrar son lineales.

Por ejemplo, considere una situación en donde una pequeña pelota se lanza al aire y se miden las alturas $h_i$ mientras haciende, durante varios momentos $t_j$. 
Los valores medidos están en la figura \ref{tab:valoresMedidos}. 
El modelo matemático que describe este fenómeno físico nos dice que, ignorando la resistencia del viento, la relación puede ser modelada como:
$$h_i = \beta_1 t_i + \beta_2 t_i^{2} + \varepsilon_i$$
\begin{table}[!h]
	\begin{center}
		\begin{tabular}{|p{2.5cm}|p{2.5cm}|}\hline
			$t_i$ & $h_1$ \\ \hline
				1 & 2 	\\ \hline
				2 & 6	\\\hline
				3 & 12  \\\hline
				4 & 20  \\\hline
				5 & 30  \\\hline
		\end{tabular}			
	\end{center}
	\caption{Valores medidos.}
	\label{tab:valoresMedidos}
\end{table}


Donde $\beta_1$ determina la velocidad inicial de la pelota, $\beta_2$ es proporcional a la constante de gravitación y $\varepsilon_i$ es debido a los errores de medición y/o a la resistencia del viento.
La regresión lineal puede ser usada para estimar los valores de $\beta_1$ y $\beta_2$  a partir de los datos medidos, aunque los datos solo sean dos variables $h_i$ y $t_i$ , solo que en esta tabla de datos de una variable independiente ($t_i$) se extiende a una tabla de datos con dos variables independientes ($t_i$ y $t_i^{2}$), esta transformación de un modelo de $n$ variables independientes a uno con $n*e$ variables independientes, donde $e$ es el grado del polinomio (el exponente más grande). En este caso $n=1$ ya que disponía de solo una variable independiente, y $e=2$ ya que el grado del polinomio que describe el modelo deseado es cuadrático. Este nuevo modelo se representa en la figura \ref{tab:transformacionModelo}.
% si da tiempo cambiar esto por poner las tablas en dos columnas
\begin{table}[!h]  
	\begin{center}
		\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{2.5cm}|}\hline
				$t_i$ & $t_i^{2}$ & $h_1$  \\ \hline
				1 & 1 & 2 	\\ \hline
				2 & 4 & 6	\\\hline
				3 & 9 & 12  \\\hline
				4 & 16& 20  \\\hline
				5 & 25& 30   \\\hline
		\end{tabular}			
	\end{center}
	\caption{ Transformación del modelo de la tabla de la figura \ref{tab:valoresMedidos}}
	\label{tab:transformacionModelo}
\end{table}

Al aplicar regresión lineal a los datos de la tabla de la figura \ref{tab:transformacionModelo} se obtiene una regresión
polinomial de modelo original representado en la tabla de la figura \ref{tab:valoresMedidos}. 
Este método de transformar el modelo para aplicar una regresión polinomial, se usó en la actividad de Implementación de regresión polinomial en la página \pageref{subsec:implementacionRegresionPolinomial}, a su ves, mas adelante se usa un método parecido a este para hacer análisis de series de tiempo, el cual esta encapsulado en la clase \texttt{WekaForecaster}, parecido en el sentido de que se toma un modelo y se le agregan variables transformándolo en otro modelo que se puede aprender por otro algoritmo de regresión o clasificación cualquiera de la librería weka.

\subsection{Redes bayesianas} \label{subsec:redesbayesianas}
El estudio de redes bayesianas es necesario ya que se usara este modelo probabilístico como técnica de predicción, más específicamente las redes bayesianas dinámicas, las cuales surgen a partir de las redes bayesianas. Una red bayesiana dinámica o temporal es un modelo estadístico y estocástico que amplía el concepto de red bayesiana.

A diferencia de este último, una red bayesiana dinámica puede representar la evolución de variables aleatorias basándose en una secuencia discreta, por ejemplo, pasos de tiempo. 
El término dinámico caracteriza el sistema modelado, no la red que no cambia.

Como tal lo que se puede calcular con una red bayesiana es la posibilidad de un evento ocurra,
por ejemplo la posibilidad de que una planta eólica produzca entre 40 y 45 kilowatts de energía, o la probabilidad de que el día este soleado, así que no arroja directamente predicciones de variables numéricas (solo de variables nominales), sin embargo se puede calcular el valor esperado a partir de estas probabilidades. Por ello, los campos numéricos son transformados a campos nominales, así que se tienen que discretizar los datos.

Un ejemplo de una red bayesiana sería en el diagnóstico médico, para determinar la probabilidad de un paciente que tiene una enfermedad con base en los síntomas. En la figura \ref{fig:redBayesianaDiagnostico} se muestra un ejemplo de una red bayesiana que modela un diagnóstico médico con base de los síntomas.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{img/redBayesianaDiagnostico.png}
	\caption{Red bayesiana que modela un problema de diagnóstico médico.}
	\label{fig:redBayesianaDiagnostico}
\end{figure}

\subsection{Series de tiempo} \label{subsec:estudiost}
Para comprender el uso de las herramientas para el análisis de series de tiempo primero se hizo una investigación sobre estas de forma general, después una investigación mas enfocada a las herramientas que existen en la librería weka.\\
Una \textit{serie de tiempo} es una secuencia de datos, que representan observaciones o
mediciones de algún fenómeno, indexados por tiempo, mas comúnmente, una
secuencia de observaciones tomadas en puntos sucesivos en el tiempo igualmente
espaciados. Por lo tanto es una secuencia de datos de tiempo discretos. Ejemplos
de una serie de tiempo son la altura de las mareas cada hora, la tasa mensual de
desempleo de los últimos 5 años, el valor de cierre diario de cierta empresa.\\
El \textit{Análisis de series de tiempo} es el proceso de usar técnicas estadísticas para modelar y explicar una serie de puntos (datos) dependientes del tiempo. El \textit{pronóstico de series de tiempo} es el proceso
de  usar un modelo para generar predicciones de futuros eventos basados en los eventos pasados conocidos.
Los datos de series de tiempo tienen un orden temporal natural, esto difiere de aplicaciones típicas de 
machine learning donde cada dato es un ejemplo independiente del concepto que se va a aprender, y el orden
de los datos en el conjunto de dato no importa. 
La librería weka a partir de su version 3.7.3 tiene un ambiente dedicado al análisis de series de tiempo que
permite que modelos de predicción sean desarrollados evaluados y visualizados. Este ambiente viene en un plugin y toma la forma de una pestaña en la interfaz gráfica ``Explorer" de weka y puede ser instalado a través del gestor de paquetes de weka, y para usar la API se puede agregar al proyecto usando Maven agregando al \texttt{POM.xml} en el elemento {\tt \lstinline$ <dependencies>$ } la dependencia que se encuentra en el código \ref{lst:dependency}.
\lstset{language=XML, label=lst:dependency, caption={[Dependencia] Dependencia} } 
\begin{lstlisting}[frame=single]  
<dependency>
	<groupId>pentaho.weka</groupId>
	<artifactId>pdm-timeseriesforecasting-ce</artifactId>
	<version>1.1.1</version>
	<scope>compile</scope>
</dependency>
\end{lstlisting} 
También es necesario agregar el repositorio en donde se encuentra esta dependencia ya que no se encuentra en el repositorio de Maven, para esto hay que agregar las líneas del código \ref{lst:repository} al elemento  {\tt \lstinline$ <repositories>$ }. 

\lstset{language=XML, label=lst:repository, caption={[Repositorio] Repositorio}} 
\begin{lstlisting}[frame=single] 
<repository>
	<id>pentaho-releases</id>
	<url>http://repository.pentaho.org/artifactory/repo/</url>
</repository>
\end{lstlisting}
El framework de weka para las series de tiempo toma un enfoque de machine learning/data mining para modelar series de tiempo transformando los datos en una forma que los algoritmos estándar de aprendizaje proposicional puedan procesar. Esto lo hace quitando el orden temporal de cada fila en el conjunto de datos, y codificando la dependencia del tiempo vía campos adicionales en cada una de las filas. 
Estos campos a veces son llamados variables rezagadas (``lagged variables") o características de interacción (``interaction features"), este proceso es similar a la regresión polinomial discutido en el reporte anterior, ya que este también necesita de dichas variables adicionales. 
Varios otros campos son generados para permitir a los algoritmos modelar tendencias y estacionalidad. 
Después de que los datos han sido transformados, cualquier algoritmo de regresión de weka puede ser aplicado para aprender el modelo, en este periodo se hicieron pruebas con el algoritmo de regresión lineal, pero cualquier método capas de predecir una variable continua puede ser aplicado, incluyendo poderosos métodos no lineales tales como  máquinas de soporte vectorial para regresión (``support vector machines"). Este enfoque de análisis de series de tiempo y pronostico de series de tiempo es a veces mas poderoso y mas flexible que técnicas estadísticas clásicas  tales como ARMA y ARIMA \cite{pentaho}.

\section{Implementación de métodos de regresión usando la librería weka}

Parte de las actividades futuras es crear un software de pronóstico de producción de energía y pronóstico de consumo de energía que después se adaptara al broker para que este pueda tomar mejores decisiones, para esto se implementaran varios algoritmos de regresión y clasificación que están en la librería weka, por lo que el primer paso hacia llegar al este objetivo es aprender a usar la librería weka.

\subsection{Librería weka}
Weka es una colección de algoritmos del área de machine learning, para tareas de minería de datos. Estos algoritmos pueden ya sea aplicarse directamente a un conjunto de datos, o llamarse desde código java mediante la API de weka.
Weka contiene herramientas para el preprocesado de datos, clasificación, regresión, clusterización, reglas de asociación y visualización. También está bien adaptado para el desarrollo de nuevos esquemas de machine learning. 

El nombre proviene de un ave no voladora de naturaleza inquisitiva que vive solamente en la isla de Nueva Zelanda.

Weka es un software de código abierto, bajo la licencia GNU General Public License.

En este periodo se hicieron varias pruebas con la librería weka, empezando por pruebas desde consola, como la de la figura \ref{fig:ejecucionAlgoritmoClasificacion}, con los datos de ejemplo que trae la librería weka, y después se desarrolló un proyecto en java que hace uso de la API de esta librería.

En la figura \ref{fig:ejecucionAlgoritmoClasificacion} se muestra como se ejecutó la clase \texttt{J48} de la librería weka, la cual es una implementación de un algoritmo de clasificación (árbol de decisión). 
El programa recibe el conjunto de datos a clasificar en el archivo \texttt{data/weather.arff}, y recibe como parámetro \texttt{-p} que significa que despliegue los resultados de la clasificación, con los atributos de principio a fin, por eso la especificación ``first-last''.

\begin{figure}[h]
	\centering
	\includegraphics[width=13cm]{img/ejecucionAlgoritmoClasificacion.png}
	\caption{Ejecución de un algoritmo de clasificación de la librería weka.}
	\label{fig:ejecucionAlgoritmoClasificacion}
\end{figure}

\subsection{Extracción de datos} 
\label{subsec:extraccion}
Los datos para hacer las siguientes pruebas fueron recabados usando el broker COLDPower corriendo en el servidor de PowerTAC, este interactúa con el broker enviándole información para que este tome decisiones y responda con diversos tipos de órdenes, tales como ordenes de compra/venta en el mercado al por mayor, creación modificación y eliminación de nuevas tarifas, órdenes de balance, entre otras. La información que el servidor le envía al broker incluye datos sobre el mercado al por mayor y el de tarifas 
(tarifas publicadas por otros brokers), mercado de balance y servicio de contabilidad, el reporte del clima,
información sobre sus clientes (información de producción y consumo de energía entre sus clientes, nuevos subscriptores, clientes que cancelaron subscripción) entre otras, en la figura \ref{fig:activity} se muestra un diagrama de la información compartida entre el broker y el servidor en cada time slot.

La información recogida mediante el broker se guardo en un archivo .arff, que es el formato que usa la librería weka para guardar los \textit{"datasets"} o conjunto de datos; este data set\footnote{Objetos de la clase weka.core.Instances que almacenan un conjunto de datos listos para ser procesados por un algoritmo de la librería weka.} incluye información sobre el clima, y sobre la producción y el consumo de cada tipo de cliente, los archivos generados fueron los siguientes: 

\renewcommand{\labelenumi}{$\bullet$ }
\renewcommand{\labelenumii}{$\bullet$ }
\begin{enumerate}
	\item Consumo:
	\begin{enumerate}
		\item BATTERY\_STORAGE.arff
		\item CONSUMPTION.arff
		\item INTERRUPTIBLE\_CONSUMPTION.arff
		\item ELECTRIC\_VEHICLE.arff
		\item STORAGE.arff
		\item THERMAL\_STORAGE\_CONSUMPTION.arff
	\end{enumerate}
	\item Producción: 
	\begin{enumerate}
		\item FOSSIL\_PRODUCTION.arff
		\item CHP\_PRODUCTION.arff
		\item PRODUCTION.arff
		\item PUMPED\_STORAGE\_PRODUCTION.arff
		\item RUN\_OF\_RIVER\_PRODUCTION.arff
		\item SOLAR\_PRODUCTION.arff
		\item WIND\_PRODUCTION.arff
	\end{enumerate}
\end{enumerate}

Como cada cliente se comporta diferente, se guardaron los kilowatts consumidos o producidos en un archivo por cada tipo de cliente para poder hacer un modelo de predicción para cada uno de ellos que se ajuste a su comportamiento, la figura \ref{fig:datos} muestra el archivo \texttt{SOLAR\_PRODUCTION.arff} 

\begin{figure}[!t]
	\centering
	\includegraphics[width=15cm]{img/datos.png}
	\caption{Datos de producción de las plantas solares. }
	\label{fig:datos}
\end{figure}	

En la figura \ref{fig:datos} se pueden ver los campos y sus tipos de datos (numéricos o nominales); el campo \texttt{kw} representa la cantidad total de kilowatts que todas las plantas solares produjeron en el último time slot, esta cantidad es positiva ya que es de producción, para los clientes de consumo esta cantidad es negativa. El campo \texttt{day} representa que día de la semana fue, este es útil para que se tome en cuenta los hábitos de consumo de ciertos tipos de clientes de consumo, como las casas, ya que puede ser que en ciertos días (ejemplo, fines de semana) consuman mas o menos energía. El campo \texttt{hour} tiene el mismo propósito, este también ayuda por ejemplo a predecir la producción de las plantas solares, pues estas tienen un pico de producción al medio día, y disminuye a 0 a medida que se acerca a la noche. El campo \texttt{temp} modela la temperatura, la cual también influye en el consumo de ciertos tipos de cliente, por ejemplo si la temperatura sube los consumidores pueden gastar energía en aire acondicionado, o si baja demasiado pueden empezar a gastar energía en calefacción o almacenamiento térmico (\texttt{thermal storage}). 
Los campos \texttt{windspeed} y \texttt{winddir} modelan la velocidad y dirección del viento, estos datos son cruciales para estimar la producción de las plantas eólicas, así como también el campo \texttt{cloudcover} que modela la nubosidad, es crucial para predecir la producción en las plantas solares. 
Por último el campo \texttt{date} representa la fecha y hora de cuando se tomaron las mediciones, esto es esencial para el modelado de la serie de tiempo, en la librería weka se le conoce también como \texttt{timestamp}.

\subsection{Implementación de regresión lineal}
Después de leer la documentación de la librería weka, se encontraron dos clases que sirven para implementar regresión lineal, la clase \texttt{SimpleLinearRegression}, y la clase \texttt{LinearRegression}; 
ambas hacen regresión lineal, la diferencia es que la clase \texttt{LinearRegression} es una generalización para $n$ variables independientes, y la clase \texttt{SimpleLinearRegression} solo lo hace con una variable independiente con el método de mínimos cuadrados.

Se programó una clase llamada \texttt{LinearRegression} para usar estas clases de dos diferentes maneras, leyendo los datos de un archivo, y generando los datos en tiempo de ejecución. 
En el código \ref{lst:exampleFromFile} se muestra una parte del código usado para correr el algoritmo con los datos que están en el archivo \texttt{lineal.arff} (línea 105).
En la línea 106 se construye el modelo, después inmediatamente se imprime el modelo, vemos en la figura \ref{fig:salidaMetodoLinearRegression} que imprime varias cosas sobre el modelo, y al final imprime la ecuación que describe la recta de mejor ajuste, esta es:
$$class = 1.9988 * a + 0.0158$$
Ya que en el archivo \texttt{lineal.arff} se especificó que la variable dependiente se llama $class$, y la variable independiente se llama $a$, este archivo se construyó con el modelo $class = 2*a + random()*0.5$, por lo cual el modelo generador por el algoritmo es muy parecido.

\lstset{language=Xml, label=lst:exampleFromFile, caption={[Método \texttt{exampleFromFile}] Método \texttt{exampleFromFile}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public static void exampleFromFile() throws Exception{
	weka.classifiers.functions.LinearRegression classifier= 
		new weka.classifiers.functions.LinearRegression();
	String info=classifier.globalInfo();
	System.out.println(info);
	Instances data=Util.instancesFromFile("lineal.arff");	
	classifier.buildClassifier(data);
	System.out.println(classifier.toString());
	Instance inst= Util.instance(50,100, data);		
	double r=classifier.classifyInstance(inst);
	System.out.println(inst.toString()+": "+ r);		
	Instances curve = data;
	PlotData2D plotdata = new PlotData2D(curve);
	plotdata.setPlotName(curve.relationName());
	plotdata.addInstanceNumberAttribute();
	ThresholdVisualizePanel tvp = new ThresholdVisualizePanel();
	tvp.setROCString("(Area under ROC = " +
		Utils.doubleToString(ThresholdCurve.getROCArea(curve),
		4)+")");
	tvp.setName(curve.relationName());
	tvp.addPlot(plotdata);	
	JFrame jf = new JFrame("Plot for: " + tvp.getName());
	jf.setSize(500,400);
	jf.getContentPane().setLayout(new BorderLayout());
	jf.getContentPane().add(tvp, BorderLayout.CENTER);
	jf.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE);
	jf.setVisible(true);
}
\end{lstlisting}
Las líneas 108 y 109 evalúan un nuevo caso usando el modelo generado, esta instancia tiene los valores de los parámetros $a=50$, $class=100$, y al usar el método \texttt{classifyInstance} en la línea 109, se calcula el valor de la variable $class$ que predice el modelo, en este caso es 99.9581, lo cual se puede ver en la figura \ref{fig:salidaMetodoLinearRegression}, en la línea que dice: 50, 100: 99.958149... la cual corresponde a la impresión de la línea 110 del método \texttt{exampleFromFile()}.
Las líneas siguientes a la 111 son para graficar en una ventana el conjunto de datos usados para crear el modelo, la ventana que creada se puede ver en la figura \ref{fig:representacionGraficaDatosLinearR}.

\subsection{Implementación de regresión polinomial} \label{subsec:implementacionRegresionPolinomial}
Debido a que la librería weka no tiene una implementación directa del algoritmo de regresión polinomial, se hizo uso del método de regresión lineal para poder hacer predicciones de un sistema de naturaleza polinomial. 
Se programó la clase \texttt{PolynomialRegression} que implementa de la interfaz \texttt{weka.classifiers.Classifier}, la cual es la interfaz base para cualquier algoritmo de regresión o clasificación.
Dentro de la clase \texttt{PolynomialRegression} se implementaron los métodos de la interfaz \texttt{Classifier}, los más importantes son los métodos \texttt{buildClassifier} y \texttt{classifyInstance}, que son para construir el modelo a partir de un conjunto de datos y para hacer una predicción dada una instancia respectivamente, 
el método \texttt{buildClassifier} se muestra en el código \ref{lst:PolynomialRegressionBuildClassifier} 
y el método \texttt{classifyInstance} se muestra en el código \ref{lst:PolynomialRegressionChangeInsClassifyIns}.

\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{img/salidaMetodoLinearRegression.png}
	\caption{Salida del método LinearRegression.exampleFromFile().}
	\label{fig:salidaMetodoLinearRegression}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{img/representacionGraficaDatosLinearR.png}
	\caption{Salida del método LinearRegression.exampleFromFile().}
	\label{fig:representacionGraficaDatosLinearR}
\end{figure}
\clearpage

\lstset{language=Xml, label=lst:PolynomialRegressionBuildClassifier, caption={[Método \texttt{PolynomialRegression.buildClassifier}] Método \texttt{PolynomialRegression.buildClassifier}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
@Override
public void buildClassifier(Instances data) throws Exception {
	if(data.classIndex()<0){
		throw new UnassignedClassException("Class index is "+
			"negative (not set)!");
	}
	ArrayList<Attribute> attribs = new ArrayList<>(
		(data.numAttributes() -1) * degree);
	int att;
	for (att = 0; att < data.numAttributes(); att++) {
		attribs.add(data.attribute(att));
	}
	for (int j = 0; j < data.numAttributes(); j++) {
		if(data.classIndex()==j)
			continue;
		for (int d = 2; d <= degree; d++) {
			StringBuilder sb= new StringBuilder(data.attribute(j)
				.name());
			sb.append("^").append(d);
			attribs.add(new Attribute(sb.toString()));
		}
	}
	Instances newInstances = new Instances(data.relationName()+
		"polynomial", attribs, data.numInstances());
	for (int in = 0; in < data.numInstances(); in++) {
		Instance inst= data.get(in);
		Instance newInst = changeInstance(inst, 
			newInstances.numAttributes());
		newInstances.add(newInst);
	}
	instances= newInstances;
	instances.setClassIndex(data.classIndex());
	classifier.buildClassifier(newInstances);
}
\end{lstlisting}

Como se está usando el método de regresión lineal para hacer regresión polinomial, primero se tiene que hacer una transformación del modelo, la cual se explica en el apartado Regresión polinomial, en la página \pageref{subsec:regresionPolinomial},
esta transformación del modelo se lleva a cabo en el código \ref{lst:PolynomialRegressionBuildClassifier} desde la línea 106 hasta la línea 131, dejando solamente a la línea 132, la cual es la que se encarga de mandar a llamar el método de regresión lineal sobre la nueva instancia del modelo.

El método \texttt{buildClassifier} hace uso del método \texttt{changeInstance}, el cual es una implementación de la transformación del modelo explicado en la sección Regresión polinomial, 
este convierte una sola fila de la tabla de la figura \ref{tab:valoresMedidos} (pagina \pageref{tab:valoresMedidos}) en una sola fila de la tabla de la figura \ref{tab:transformacionModelo} (pagina \pageref{tab:transformacionModelo}), agregándole los parámetros que necesarios para hacer la regresión polinomial. 
El método \texttt{changeInstance} se muestra en el código \ref{lst:PolynomialRegressionChangeInsClassifyIns}, donde también se muestra la implementación del método \texttt{classifyInstance}, el cual también hace uso del método \texttt{changeInstance}, para convertir instancia (única medición de las variables independientes) en una instancia a la cual se le puede aplicar la regresión.
%aqui podria ir una explicacion al metodo changeInstance
En la linea 101 del código \ref{lst:PolynomialRegressionChangeInsClassifyIns} se crea el arreglo que representara a la instancia transformada (una fila de la tabla), el for de la linea 103 llena los primeros elementos con los de la instancia original, el for de la linea 106 llena los demás elementos con 
variables que representan potencias de las variables originales (excepto por la variable de clase por eso el if de la linea 107), de acuerdo con el grado elegido (atributo \texttt{degree}), de tal manera que si la instancia consta de las variables $\{x1,x2,y\}$ donde y es la variable de clase, y el grado es 3, la instancia resultante tendrá las variables $\{x1,x2,y,x1^2,x1^3,x2^2,x2^3\}$ 

La clase \texttt{PolynomialRegression} se prueba desde el \texttt{main} de la clase principal del proyecto el cual se muestra en el código \ref{lst:mainPolynomialRegression}, en este se construye un conjunto de datos modelados por la ecuación $y= x^{2}$ (lineas 102-107), luego se construye el modelo en la línea 108 y de las líneas 109 a la 112 se hace un pronóstico para una instancia en la cual la variable independiente es igual a 20, y según el modelo que se usó para construir los datos, la variable independiente debería de ser $20^{2}= 400$.
El resultado de correr este código fue 399.9999997, una aproximación bastante cercana, con un error casi despreciable, lo cual demuestra que la implementación del algoritmo es buena.

\lstset{language=Xml, label=lst:PolynomialRegressionChangeInsClassifyIns, 
caption={[Métodos \texttt{changeInstance} y \texttt{classifyInstance} de la clase \texttt{PolynomialRegression}] 
Métodos \texttt{changeInstance} y \texttt{classifyInstance} de la clase \texttt{PolynomialRegression}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
protected Instance changeInstance(Instance inst, int numAtt){
	double values[]=new double[numAtt];
	int att;
	for (att = 0; att < inst.numAttributes(); att++) {
		values[att]=inst.value(att);
	}
	for(int j=0;j<inst.numAttributes();j++){
		if(inst.classIndex() == j){
			continue;
		}
		double aux= values[j];
		for (int d= 2; d <= degree; d++) {
			aux*=values[j];
			values[att++]= aux;
		}
	}
	Instance newInst = new DenseInstance(1.0, values);
	return newInst;
}
@Override
public double classifyInstance(Instance instance) 
		throws Exception {
	instance.setDataset(instances);
	Instance newInst= changeInstance(instance,
		instances.numAttributes());
	classifier.setEliminateColinearAttributes(false);
	return classifier.classifyInstance(newInst);
}
\end{lstlisting}




\lstset{language=Xml, label=lst:mainPolynomialRegression, 
caption={[Main para probar la clase PolynomialRegression \texttt{PolynomialRegression}] 
Main para probar la clase PolynomialRegression \texttt{PolynomialRegression}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public static void main(String[] ar){
	PolynomialRegression classifier= new PolynomialRegression(3);
   	double datos[][]=new double[100][2];
  	for (int i = 0; i < datos.length; i++) {
		datos[i][0]= i;
		datos[i][1]= i*i;
	}
   	Instances ins= instancesFromArrays(datos);
   	classifier.buildClassifier(ins);
   	double x[]=new double[2]{20,400};
   	double y=classifier.classifyInstance(
   		new DenseInstance(1.0,x));
   	System.out.println("y= "+y);   	
}
\end{lstlisting}

\subsection{Implementación de algoritmo de series de tiempo} \label{subsec:implementacionSeries}

La librería weka dispone de una implementación de un algoritmo para analizar series de tiempo el cual toma como base otro algoritmo de la librería que pueda manejar datos numéricos, tal como se vio en la sección \ref{subsec:estudiost} en la \hyperref[subsec:estudiost]{página \pageref{subsec:estudiost}}, este módulo también dispone de una clase para graficar las series de tiempo el cual se uso para ayudar a analizar los resultados de manera mas intuitiva.\\
En la \hyperref[fig:diagramaUml]{figura \ref{fig:diagramaUml}} 
se muestra un diagrama con la implementación del algoritmo de series de tiempo en la clase \texttt{TimeSeries}, el cual hereda de la clase \texttt{AbstractClassifier} para heredar los métodos base de cualquier algoritmo de regresión o clasificación de la librería, y poder usarla junto con otras clases de la librería. La clase implementa de \texttt{TSForecaster} ya que esta interfaz es la que define un analizador de series de tiempo, y esto permite que se use con otras clases de la librería como \texttt{JFreeChartDriver} que sirve para graficar los resultados del análisis, o \texttt{TSEvaluation} que sirve para evaluar el modelo generado.
\begin{figure}[!b]%Ambiente ’figure’
	\centering
	%imagen sin escalar
	\includegraphics[width=15cm]{img/diagramaUml.png}
	\caption{Diagrama UML de las clases implicadas a la clase \texttt{TimeSeries}. }
	\label{fig:diagramaUml}
\end{figure}

El objeto \textit{forecaster} de la clase \texttt{WekaForecaster} es el motor de esta clase, implementa el algoritmo de pronóstico de series de tiempo. Hace uso de la clase \texttt{TSLagMaker} que es la que crea todas las variables rezagadas o lagged variables, la creación de atributos o campos periódicos, etc.
Los métodos heredados de la clase \texttt{AbstractClassifier} son:
%\renewcommand{\labelenumi}{$\bullet$ }
%\renewcommand{\labelenumii}{$\bullet$ }
\begin{enumerate}
	\item \texttt{buildClassifier(Instances data)} es el método que realiza el análisis de la serie de tiempo y construye el modelo 		a partir de los datos contenidos en el objeto data de la clase \texttt{Instances} que se le paso como parámetro.
	
	\item \texttt{classifyInstance(Instance instance)} es el método que realiza la predicción, recibe un objeto \texttt{Instance}, del cual 	extrae la fecha y retorna una predicción de la variable objetivo para esa fecha.
	
	\item  \texttt{distributionForInstance(Instance instance)} se usa cuando el algoritmo de clasificación/regresión tiene una 				variable objetivo (el atributo cuyo valor intenta calcular) de tipo nominal (discreto) como es el caso de la red bayesiana, que 		retorna un valor de probabilidad para cada uno de los posibles valores de la variable, así que en este algoritmo no se usa.
\end{enumerate}
Los métodos implementados de la interfaz \texttt{TSForecaster} son los que le dan la funcionalidad para el análisis y pronostico de series de tiempo a la clase, \textit{``TSForcaster"} es abreviación de \textit{time series forecaster} o \textit{pronosticador de series de tiempo}. Los métodos de esta interfaz son: 
\begin{enumerate}
	\item \texttt{buildForecaster(Instances insts, PrintStream... progress)} analiza el conjunto de datos en el objeto
			\texttt{insts} y crea el modelo que describe la serie de tiempo. El parámetro \texttt{progress} es un arreglo de flujos 
			donde se imprimirán mensajes de depuración acerca de la ejecución del método, un ejemplo es pasar como parámetro
			\texttt{System.out}.
			
	\item \texttt{getAlgorithmName()} retorna el nombre de la clase que se esta usando para aprender el modelo, en el caso del
			código \ref{lst:tsevaluation}, este método imprimiría: \\ \texttt{weka.classifiers.functions.LinearRegression}.
			
	\item \texttt{primeForecaster(Instances insts)} prepara el modelo (potencialmente) entrenado con datos conocidos hasta el punto 
			actual, para que a partir de ese punto se hagan predicciones hacia el futuro. Se puede usar el mismo conjunto de datos
			usado en el entrenamiento. 
			
	\item \texttt{reset()} reinicia el modelo.
	
	\item \texttt{forecast(int numSteps, PrintStream... progress)} retorna una lista de \texttt{numSteps} listas, donde cada una
			representa las predicciones de la(s) variable(s) objetivo hasta \texttt{numSteps} unidades de tiempo hacia el futuro,
			información del avance del	proceso se imprime en los objetos \texttt{progress}.
\end{enumerate}

La clase (\texttt{TSEvaluation}) automatiza la evaluación del modelo generado, en el código \ref{lst:tsevaluation} se muestra un ejemplo de su uso. 

\lstset{language=Java, label=lst:tsevaluation, caption={[TSEvaluation] Evaluación con la clase \texttt{TSEvaluation}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
Instances datos = Util.instancesFromFile("SOLAR_PRODUCTION.arff");
TimeSeries timeseries = new TimeSeries();
timeseries.setTimestamp("date");
timeseries.setFieldsToForecast("kw");
timeseries.setBaseLearner(new LinearRegression());
int numInstPred=24, size=datos.numInstances();
Instances train = new Instances(datos, 0, size - numInstPred);
Instances test = new Instances(datos,size-numInstPred,numInstPred);
try {
	TSEvaluation evaluation= new TSEvaluation(train, test);		
	PrintStream prog[]=new PrintStream[0];
	evaluation.setHorizon(24);
	evaluation.setPrimeWindowSize(24);
	evaluation.evaluateForecaster(timeseries, true,prog);
	System.out.println(
		evaluation.printPredictionsForTestData("Resultados","kw",1));
	System.out.println(evaluation.toSummaryString());
} catch (Exception e) {
	e.printStackTrace();
}
\end{lstlisting}
En la línea 100 se cargan los datos del archivo \texttt{SOLAR\_PRODUCTION.arff}, de la línea 101 a la 104 se crea y configura el objeto de la clase \texttt{TimeSeries} que realizara el análisis y construcción del modelo, a este se le tiene que decir que campo es el que representa la dimension del tiempo en la serie (línea 102), también se tiene que especificar cuales son los campos objetivos (los que se quieren predecir), en este caso se eligió los kilowatts producidos por la planta solar (línea 103), y lo mas importante se tiene que especificar el algoritmo de aprendizaje a usar, para esta prueba se eligió la regresión líneal (línea 104).
De la línea 105 a la 107 se separan los datos del archivo \texttt{SOLAR\_PRODUCTION.arff} en dos partes, la mayoría se pone en el objeto \texttt{train} que es el que se usara para construir el modelo, este contiene todos excepto los últimos 24 registros, estos últimos registros se ponen en el archivo \texttt{test}, que sera usado para probar el modelo generado y medir su precision.
En la línea 109 se crea el objeto \texttt{evaluation} de la clase \texttt{TSEvaluation} pasandole los datos de entrenamiento y pruebas. Como no se desea imprimir el progreso se crea el arreglo \texttt{prog} de tamaño 0 en la línea 110 y  antes de ejecutar la evaluación se ejecutan las líneas 111 y 112 que especifican el numero de unidades de tiempo a predecir.
\\Por ultimo se ejecuta el método \texttt{evaluateForcaster()} que recibe el objeto que contiene el modelo de la serie de tiempo (este debe implementar la interfaz \texttt{TSForecaster}), un booleano que significa que debe construir el modelo, y el arreglo de flujos donde se imprimirá el progreso. 
Lo que hace la clase \texttt{TSEvaluation} es evaluar hacer varias predicciones un paso adelante, luego predicciones 2 pasos adelante, hasta llegar a predicciones $n$ pasos hacia el futuro, en este caso $n=24$.
Los resultados se imprimen en las líneas 104 y 106, la primera imprime los valores predichos $n$ pasos hacia adelante por el modelo, su valor real y el error que hubo, la segunda línea imprime un resumen de los resultados, que consta de el valor del error medio absoluto y la raíz del error cuadrático medio de cada conjunto de predicciones a $n$ pasos. En la  \hyperref[fig:resultadosEvaluacion]{figura \ref{fig:resultadosEvaluacion}} se muestra la salida de este código. 

\begin{figure}[!h]
	\centering
	\includegraphics[width=15cm]{img/resultadosEvaluacion.png}
	\caption{Resultados de la evaluación con la clase TSEvaluation. }
	\label{fig:resultadosEvaluacion}
\end{figure}
%\clearpage
La clase \texttt{TSEvaluation} resulta útil para medir la exactitud que tienen las predicciones de acuerdo a cuantos pasos en el futuro se esta prediciendo, no obstante necesitamos una medida de la exactitud para una sola predicción de $n$ pasos hacia el futuro, en lugar de mediciones agrupadas por pasos, es decir $n$ predicciones de 1 paso, $n-1$ predicciones de 2 pasos, $n-2$ predicciones de 3 pasos, tal como lo hace esta clase, por lo que se opto por crear métodos propios para evaluar la exactitud de los resultados, y métodos para graficar los resultados.
El \hyperref[lst:maincustomtest]{código \ref{lst:maincustomtest}} realiza una evaluación de las predicciones a 24 horas generadas por el modelo, y despliega el error medio absoluto junto con otras métricas de evaluación de la exactitud del modelo generado, ademas de mostrar una ventana con un gráfico representando la serie de tiempo real, y la parte generada por el modelo.

\lstset{language=Java, label=lst:maincustomtest, caption={[Evaluación personalizada de series de tiempo] Evaluación personalizada de series de tiempo},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
Instances datos = Util.instancesFromFile("SOLAR_PRODUCTION.arff");
String targetName="kw" ;
String xaxis="date";

TimeSeries timeseries = new TimeSeries();
timeseries.setDebug(true);
timeseries.setTimestamp(xaxis);
timeseries.setFieldsToForecast(targetName);
timeseries.setBaseLearner(new LinearRegression());

String period="day=>=*:*:*:*:*:*:*:6:*:* <=*:*:*:*:*:*:*:18:*:*";
timeseries.forecaster.setTSLagMaker(new NewLagMaker());
NewLagMaker lag=(NewLagMaker)timeseries.forecaster.getTSLagMaker();
lag.setIncludePowersOfTime(false);
lag.setIncludeTimeLagProducts(false);
lag.setPrimaryPeriodicFieldName("hour"); 
lag.addCustomPeriodic(period);

int numInstPred=24;
int size=datos.numInstances();
Instances train = new Instances(datos, 0, size - numInstPred);
Instances test = new Instances(datos,size-numInstPred,numInstPred);
timeseries.setHorizon(24);
timeseries.setPrimeWindowSize(24);
List<ErrorModule> preds= timeseries.test(train, test);
JFreeChartDriver chart = new JFreeChartDriver();
List<Integer> stepsToPlot= new ArrayList<>(2);
stepsToPlot.add(1);
JPanel graph;
//graph= Util.graphSeries(preds.get(0), datos, targetName, xaxis);
graph= chart.getGraphPanelSteps(timeseries, preds, targetName,
	stepsToPlot, 0, train);
JFrame jf = new JFrame("Time series");
jf.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE);
jf.setSize(800, 600);
jf.getContentPane().setLayout(new BorderLayout());
jf.getContentPane().add(graph, BorderLayout.CENTER);
jf.setVisible(true);
System.out.println("Mean absolute error: " +timeseries.getMAE());
System.out.println("Mean squared error: "+ timeseries.getMSE());
System.out.println("Root mean squared error: "
	+ timeseries.getRMSE());
System.out.println("Mean absolute percentage error: " 
	+ timeseries.getMAPE());
\end{lstlisting}

En el \hyperref[lst:maincustomtest]{código \ref{lst:maincustomtest}}, de las líneas 100 a la 102 esta especificada la configuración general, la cual es el nombre del archivo donde sacar los datos, el nombre de la variable objetivo o campo a pronosticar, y el campo de fecha que le daré la característica de serie de tiempo a los datos. Es necesario especificar porque puede ser que tenga mas de un campo de fecha y solo uno representa el eje temporal, o que no tenga campo de fecha tipo date, y tenga uno tipo numeric.\\
De la línea 104 a la 108 se crea el objeto de la clase \texttt{TimeSeries} que hará el análisis de la serie y el pronostico, se le especifica los datos anteriormente mencionados y el algoritmo base para aprender el modelo que en este caso es regresión lineal. En las líneas 104-116 se le da información extra sobre la serie de tiempo, al ser el conjunto de datos la producción en kw de una planta solar, sabemos que la producción va a tener un ciclo constante de día y noche, produciendo energía entre las 6 am y las 6 pm, por lo que se le especifica este horario en la línea 110.	De la línea 118 a la 123 se especifican que datos se van a usar para entrenamiento (los primeros de 0 al tamaño-24) y cuales se van a usar para pruebas (los últimos 24), tal como se hizo en el \hyperref[lst:tsevaluation]{código \ref{lst:tsevaluation}}, la línea 124 es la que manda a llamar la función que hace la evaluación con los datos de entrenamiento y pruebas, usa los primeros para entrenar y construir un modelo, y los segundos para comparar el pronostico que se hizo con el modelo y calcular métricas de error.\\
Después viene la parte de graficar los resultados, esto es de la línea 125 a la 137. Hay dos maneras de graficar los resultados, usando la clase \texttt{JFreeChartDriver} y pasandole al método \texttt{getGraphPanelSteps} un  objeto que implemente la interfaz \texttt{TSForecaster} (por eso la clase \texttt{TimeSeries} implementa esta interfaz), las predicciones a graficar, el nombre de la variable objetivo a graficar, un arreglo con los indices de las pruebas a graficar, cuyas pruebas salieron de la clase \texttt{TSEvaluation} y que cada una tiene los datos de $n$ pasos hacia el futuro, como esta clase esta personalizada, no retorna pruebas agrupadas por el numero de pasos, retorna una sola prueba con los $n=24$ pasos hacia el futuro, por lo que solo se le pasa el indice 0; por ultimo se le pasa a este método el entero \textit{\texttt{offset}} y los datos de entrenamiento, que es, respectivamente, de donde empezar a graficar (0 significa desde el principio) y los datos reales que se compararan con los pronosticados. La gráfica generada por la clase \texttt{JFreeChartDriver} se puede ver en la 
\hyperref[fig:JFreeChartDriver]{figura \ref{fig:JFreeChartDriver}}, 
pero como también se deseaba ver los datos anteriores, se escribió el método \texttt{Util.graphSeries} para esto, y si se comenta la línea 130 y se des comenta la línea 129, este método entrara en acción y graficara la ventana que aparece en la \hyperref[fig:Util.graphSeries]{figura \ref{fig:Util.graphSeries}}. Esta figura muestra una imagen general de todos los datos de entrenamiento, es decir los datos desde el 28 de abril hasta el 13 de mayo, estos aparecen en azul.

%\begin{SCfigure}[0.5][!h]
\begin{wrapfigure}{l}{0.65\textwidth}
	\caption{Resultados de las métricas de error. }
	\includegraphics[width=10cm]{img/resultadosSerieDeTiempo1.png}
	\label{fig:resultadosMetricasSerieTiempo}
%\end{SCfigure}
\end{wrapfigure}
Los datos en rojo que aparecen de el 13 al 14 de mayo, son los datos pronosticados por el modelo, y los datos en azul del 13 al 14 de mayo son los datos de pruebas, es decir, lo que en realidad pasó en ese periodo y se usaron para calcular el error, lo resultados de las métricas de error aparecen en la \hyperref[fig:resultadosMetricasSerieTiempo]{figura \ref{fig:resultadosMetricasSerieTiempo}}.

\begin{figure}[!b]
	\centering
	%imagen sin escalar
	\includegraphics[width=13cm]{img/JFreeChartDriver.png}
	\caption{Ventana generada con la clase JFreeChartDriver. }
	\label{fig:JFreeChartDriver}
\end{figure}
\begin{figure}[!h]
	\centering
	%imagen sin escalar
	\includegraphics[width=13cm]{img/UtilgraphSeries.png}
	\caption{Ventana generada por el método personalizado Util.graphSeries.}
	\label{fig:Util.graphSeries}
\end{figure}

\subsection{Implementación de redes bayesianas} \label{subsec:implementacionRedes}
\subsubsection{Filtrado}
\label{sec:filtrado}
Ya que las redes bayesianas solo pueden tratar con probabilidades de datos dizcretos, como se vio en la 
\hyperref[subsec:redesbayesianas]{ sección \ref{subsec:redesbayesianas}} de la pagina \pageref{subsec:redesbayesianas}, se necesita aplicar un filtro a los datos que discretize los campos numéricos para que la red bayesiana pueda crear un modelo de los datos, así que se programaron una serie de funciones con este propósito. Se hizo el método \texttt{discretizeData} en la clase \texttt{BayesianNetwork} que a su vez hizo uso del método \texttt{numericToNominal} para discretizar cada uno de los campos del data set, este método se ve en el  \hyperref[lst:numericToNominal]{código \ref{lst:numericToNominal}}.
La función recibe el conjunto de datos, el indice del atributo a discretizar y el número de posibles valores para la variable discreta (en cuantos partes iguales dividir el intervalo entre el valor mínimo y el máximo de la variable).
Lo que hace esta función primero es encontrar el valor mínimo y el máximo en la variable (líneas 101-106), después calcular de que tamaño van a ser cada uno de los rangos que van a representar las variables discretas, y con esto después crea las etiquetas de los rangos (en el for de la línea 114-130) y después dizcretiza los valores de las variables eligiendo un rango en la que el valor de cada variable cae (línea 134-144).
Así que los datos de la \hyperref[fig:datos]{figura \ref{fig:datos}} de la pagina \pageref{fig:datos} después de discretizarse se convierte en los datos de la \hyperref[fig:datosDiscretizados]{figura \ref{fig:datosDiscretizados}}. 

\lstset{language=Java, label=lst:numericToNominal, caption={[Método \texttt{numericToNominal} de la clase \texttt{BayesianNetwork}] Método \texttt{numericToNominal} de la clase \texttt{BayesianNetwork}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
Instances numericToNominal(Instances data, int att, int n){
	double maxi=Double.NEGATIVE_INFINITY, mini= Double.MAX_VALUE;
	for (int i = 0; i < data.numInstances(); i++) {
		Instance act=data.get(i);
		maxi= Math.max(act.value(att), maxi);
		mini= Math.min(act.value(att), mini);
	}
	double separacion = (maxi - mini)/ n;
	labelValues = new double[n+1];
	if(debug)
		System.out.println("min "+mini+", max "+maxi+" separacion "
			+separacion);
	labelData.put(att, new LabelData(mini, separacion, n));
	ArrayList<Attribute> arr= new ArrayList<>(data.numAttributes());
	for (int i = 0; i < data.numAttributes(); i++) {
		if(i==att){
			ArrayList<String> labels = new ArrayList<>(n+1);
			for (int j = 0; j < n; j++) {
				labels.add("["+(mini + separacion*(j))+"-" 
					+ (mini + separacion*(j+1)) +")");
				labelValues[j]= mini + separacion*(j+0.5);
			}
			labelValues[n] = mini + separacion*(n+0.5);
			labels.add("["+maxi +"-inf)");
			if(debug)
				System.out.println("labels: " +labels);
			arr.add(new Attribute(data.attribute(att).name(),labels));
		} else{
			arr.add(data.attribute(i));
		}
	}
	Instances newInst= new Instances(data.relationName(),arr,
		data.numInstances());
	newInst.setClassIndex(data.classIndex());
	for (int c = 0; c < data.numInstances(); c++) {
		Instance act=data.get(c);
		double values[] =  new double[data.numAttributes()];
		for (int i = 0; i < data.numAttributes(); i++) {
			if(i==att){
				values[i]= ((act.value(i) - mini) /separacion);
				values[i]= Math.min(n, values[i]);
			} else{
				values[i]= act.value(i);
			}
		}
		newInst.add(Util.instance(values, newInst));
	}
	return newInst;
}
\end{lstlisting}

\begin{figure}[!t]
	\centering
	%imagen sin escalar
	\includegraphics[width=17cm]{img/datosDiscretizados.png}
	\caption{Conjunto de datos después de haber sido discretizados.}
	\label{fig:datosDiscretizados}
\end{figure}

Se puede observar que en la declaración de campos numéricos ahora son de tipo nominal, y los distintos valores que pueden tomar (están entre \{\} después de la declaración del atributo) son etiquetas que representan rangos numéricos con el formato [A-B), donde A y B son variables numéricas de tipo doble.\\
Los datos ahora no aparecen como un número, sino como un rango, y esto permite a la red bayesiana construir el modelo, el cual sera usado para calcular la probabilidad de que una variable caiga en un rango determinado, y esto sera usado para calcular el valor esperado.

\subsubsection{Aplicación del algoritmo}
Al tener el cálculo de las posibilidades de que eventos ocurran se calcula el valor esperado
usando los datos de la distribución de probabilidades calculada por la red bayesiana, por ejemplo, para el caso de que se tenga la  variable que representa los kilowatts producidos en una planta eólica $KW$ , la cual fue discretizada en $n=3$ rangos: 
$KW= \{[0-2), [2-4), [4-\infty)\}$, y la distribución de probabilidad es: 
$DP= \{0.2,~0.5,~0.3\} $; lo cual significa que la probabilidad de que la planta produzca entre 0 y 2 kilowatts es de 0.2, la probabilidad de que se produzca de 2 a 4 kilowatts es de 0.5 y la probabilidad de que se produzca mas de 6 kilowatts es de 0.3. 
Usando estas probabilidades se calcula el valor esperado $\mathbb{E}(KW)$ con la siguiente formula: 
\begin{equation}  \label{eq:valorEsperado}
	\mathbb{E}(KW) = \sum_{i=0}^{n}{LB}_i \cdot {DP}_i 
\end{equation}
Donde $LB$ son las etiquetas de clase de la variable $KW$, es decir un valor que representa al rango, en este caso seria 
$LB=\{1, 3, 6\}$. 
Por lo cual el resultado del valor esperado para este ejemplo seria: $1*0.2 + 3*0.5 + 6*0.3= 3.5$.
En el \hyperref[lst:testAndTrainBayes]{ código \ref{lst:testAndTrainBayes}} se muestra la implementación de este algoritmo desde el filtrado de los datos discutido en la sección de filtrado en pagina \pageref{sec:filtrado} hasta el calculo del valor esperado, y evaluación del modelo para calcular sus métricas de error.

La función que se manda a llamar desde el \texttt{main} es \texttt{trainAndTest}, esta lo primero que hace es aplicarle el filtro de discretización a los datos, con las funciones discutidas en la sección de \hyperref[sec:filtrado]{ filtrado \ref{sec:filtrado}} de la pagina \pageref{sec:filtrado}, y después de esto manda los datos filtrados a la función \texttt{trainAndTestFiltered} en la línea 107, en esta función se manda a construir el modelo con la función \texttt{buildClassifierFiltered} (línea 112), esta función se encuentra implementada en las líneas 133 a la 143, y lo que hace es inicializar los algoritmos de estimación de probabilidades (\texttt{estimator}) y de construcción de la estructura (\texttt{search}) si no hay sido inicializados desde el exterior, y después de esto manda a llamar el método buildClassifier de la clase \texttt{BayesNet}, que es la clase de la librería weka que construye el modelo.\\
Después de construir el modelo, se selecciona el campo o variable a pronosticar, que en este caso se elige la variable de clase (líneas 114-119) por lo que se debe de asignar desde afuera antes de llamar a la función \texttt{trainAndTest} y justo empieza el proceso de pronóstico en el for de la línea 120 a la 128, este for recorre los datos \texttt{test}, que son los que siguen en la línea de tiempo después de los datos \texttt{train} y son los valore reales de lo que ocurrió, para cada uno de estos se hace una predicción (línea 121) usando la función \texttt{classifyInstanceFiltered}, la cual esta implementada en las líneas 144-152 e implementan la ecuación \ref{eq:valorEsperado}. Luego en las líneas 123 a 127 se guardan los valores y se calcula el error con el valor predicho y el valor real (línea 127), esta función lo que hace es sacar la sumatoria y esta implementada en las líneas 153-160, a su vez esta sobre cargada para recibir un entero y terminar el calculo de error, esta función se manda a llamar justo después del for en la línea 129 y esta implementada en las líneas 161 a la 166.

Este código se ejecuta en un \texttt{main} parecido al del \hyperref[lst:maincustomtest]{ código \ref{lst:maincustomtest}}, así que podemos comparar los datos pronosticados con los datos reales de manera gráfica. En la  \hyperref[fig:redBayesianaRes]{ figura \ref{fig:redBayesianaRes}} podemos ver una ventana con los resultados del pronostico usando la red bayesiana, y en la \hyperref[fig:redBayesianaResZoom]{ figura \ref{fig:redBayesianaResZoom}} podemos ver un acercamiento a los datos pronosticados.

\lstset{language=Java, label=lst:testAndTrainBayes, caption={[Métodos para entrenar y evaluar una red bayesiana (clase \texttt{BayesianNetwork})] Métodos para generar predicciones y evaluar el modelo generado de la clase \texttt{BayesianNetwork}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public List<ErrorModule> trainAndTest(Instances train,
		Instances test) throws Exception {
	train=discretizeData(train);
	Instances testFiltered= new Instances(test);
	for (int i = 0; i < test.size(); i++) {
		discretize(testFiltered.get(i));
	}
	return trainAndTestFiltered(train, testFiltered, test);
}
public List<ErrorModule> trainAndTestFiltered(Instances train, 
		Instances testFiltered, Instances test) throws Exception {
	List<ErrorModule> preds= new ArrayList<>(1);
	buildClassifierFiltered(train);

	String fieldsToForecast= train.classAttribute().name();
	ErrorModule em= new ErrorModule();
	List<String> f=new ArrayList<String>();
	f.add(fieldsToForecast);
	em.setTargetFields(f);
	Attribute att= testFiltered.attribute(fieldsToForecast);
	for (int i = 0; i < testFiltered.numInstances(); i++) {			
		double value= classifyInstanceFiltered(testFiltered.get(i));
		List<NumericPrediction> predsForStepI = new ArrayList<>(1);
		NumericPrediction pred= 
			new NumericPrediction(test.get(i).value(att), value);
		predsForStepI.add(pred);
		em.evaluateForInstance(predsForStepI, test.get(i));
		calculateErrors(pred.actual(), pred.predicted());
	}
	calculateErrors(testFiltered.numInstances());
	preds.add(em);
	return preds;
}
protected void buildClassifierFiltered(Instances filteredData)
		throws Exception{
	if(estimator==null)
		estimator=new SimpleEstimator();
	if(search==null)
		search=new K2();
	this.data = filteredData; 
	red.setEstimator(estimator);
	red.setSearchAlgorithm(search);
	red.buildClassifier(filteredData);
}
protected double classifyInstanceFiltered(Instance instance) 
		throws Exception{
	double distr[]=red.distributionForInstance(instance);
	double r=0;
	for (int i = 0; i < distr.length; i++) {
		r+= labelValues[i]*distr[i];
	}
	return r;
}
protected void calculateErrors(double actual, double predicted) {
	double diff= predicted- actual;
	MAE+= Math.abs(diff);
	MSE+= diff*diff;
	if(actual!=0){
		MAPE+= Math.abs(diff /actual);
	}
}
protected void calculateErrors(int n){
	MAE= MAE/n;
	MSE= MSE/n;
	RMSE= Math.sqrt(MSE);
	MAPE=MAPE/n;
}
\end{lstlisting}

\begin{figure}[!h]
	\centering
	%imagen sin escalar
	\includegraphics[width=13.5cm]{img/redBayesianaRes.png}
	\caption{Gráfica de resultados de pronostico de red bayesiana.}
	\label{fig:redBayesianaRes}
\end{figure}

\begin{figure}[ht]
	\centering
	%imagen sin escalar
	\includegraphics[width=13.5cm]{img/redBayesianaResZoom.png}
	\caption{Acercamiento a conjunto de datos después de haber sido discretizados.}
	\label{fig:redBayesianaResZoom}
\end{figure}

\subsection{Implementación del meta-algoritmo bagging}
El meta-algoritmo bagging es otra opción a las redes bayesianas ya que al igual que estas, es un algoritmo de clasificación (cuando se usa con otro algoritmo de clasificación, como en este caso) que toma en cuenta los valores de las variables de una instancia para poder "clasificar" la variable de clase, es decir, en el caso de este proyecto, toma en cuenta las variables del clima de un cierto momento en el tiempo y usa estos datos para calcular el numero de kilowatts esperados para ese momento.

Implementar este método usando la librería weka es mas fácil que implementar la red bayesiana, ya que no hace falta preprocesar los datos de entrada (discretizarlos) o los de salida (calcular el valor esperado con base a las probabilidades), por lo que no fue necesario hacer una clase que envuelva este comportamiento, y se uso directamente la clase \texttt{weka.classifiers.meta.Bagging}, permitiendo que su uso sea tan simple como el que se ve en el código \ref{lst:testBaggin}, 
en donde se usa con un árbol de decisión como algoritmo base, este se encuentra encapsulado en la clase \texttt{weka.classifiers.trees.REPTree}, en la linea 102 vemos como se asigna como algoritmo base, en la linea 106 se leen los datos del archivo \texttt{SOLAR\_PRODUCTION.arff}, 
la variable \texttt{numPred} de la linea 108 guarda el numero de predicciones que se harán, según esto se crearan los datasets de entrenamiento y de pruebas (lineas 112, 113) donde el entrenamiento es todo el data set leído en la linea 106 y las pruebas son los últimos \texttt{numPred} registros, en este caso, los últimos 24. 
En la linea 116 se construye el clasificador con los datos de entrenamiento, y en el for de la linea 118 se imprimen las predicciones hechas con este clasificador, junto con los valores reales y la fecha.
Al final se imprime el error medio absoluto y el tiempo en milisegundos que se tardo en correr el algoritmo, un ejemplo de esta salida se encuentra en la figura \ref{fig:salidaConsolaBagging}.

\lstset{language=Java, label=lst:testBaggin, caption={[Método \texttt{createSearchAlgorithms} de la clase \texttt{TimeSeries}] Método \texttt{createSearchAlgorithms} de la clase \texttt{TimeSeries}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
protected static void testBaggin(){
	Bagging bg = new Bagging();
	bg.setClassifier(new REPTree());
	String target="kw",xaxis="date",file="SOLAR_PRODUCTION";
	long time= System.currentTimeMillis();
	try { 
		Instances datos = Util.instancesFromFile(file+".arff");
		
		int numPred=24;
		int classIndex= datos.attribute(target).index();
		datos.setClassIndex(classIndex);
		int size=datos.numInstances();
		Instances train = new Instances(datos, 0, size - numPred);
		Instances test=new Instances(datos, size-numPred,numPred);
		Attribute atX = test.attribute(xaxis);
		double mae= 0, real, pred;
		bg.buildClassifier(train);
		
		for (int i = 0; i < test.numInstances(); i++) {
			Instance ins = test.get(i);
			real=ins.classValue();
			pred= bg.classifyInstance(ins);
			System.out.printf("%s %.3f %.3f\n",
				atX.formatDate(ins.value(atX)),real, pred );
			mae+= Math.abs(real-pred);
		}
		mae/= test.numInstances();
		System.out.println("Mean absolute error (MAE): " + mae+ 
			" tm " + (System.currentTimeMillis()- time));
	} catch (Exception e) {
		e.printStackTrace();
	}
}
\end{lstlisting}

\begin{figure}[ht]
	\centering
	\includegraphics[width=13.5cm]{img/salidaConsolaBagging.png}
	\caption{Salida de la ejecución del método bagging (código \ref{lst:testBaggin}).}
	\label{fig:salidaConsolaBagging}
\end{figure}

\section{Comparación de algoritmos} \label{sec:comparacion}
Una de las principales diferencias entre una red bayesiana con una la serie de tiempo es que el pronóstico con red bayesiana requiere datos sobre el futuro (los otros datos que no son la variable a predecir), es decir los datos del clima. Otros campos como los de hora y día de la semana si se conocen al momento de querer predecir una fecha y hora, pues si se sabe que fecha y hora se quieren predecir, se puede saber que día de la semana y que hora sera.
Las pruebas que se hicieron aquí fueron con los datos reales, es decir se ocuparon los datos del clima como si ya supiéramos como estará el clima, pero en la realidad lo que se usara para implementar la solución en el broker, serán los datos del reporte del clima dado por el servidor.

\subsection{Series de tiempo} \label{subsec:compSeries}
Recordando el funcionamiento interno del la implementación de series de tiempo de la libreria weka, esta transforma el modelo agregándole variables de arrastre, y después aprende el modelo con un algoritmo base, el algoritmo que se uso en las demostraciones pasadas fue el de regresión lineal, implementado en la clase 
\texttt{weka.classifiers.functions.LinearRegression}, lo siguiente que se hizo fue probar cual de los algoritmos posibles es el que da mejores resultados, así que se comenzó por hacer un arreglo llamado \texttt{baseLearners} en la clase \texttt{TimeSeries}, el cual se inicializo con la función \texttt{TimeSeries.createSearchAlgorithms()} la cual aparece en el 
\hyperref[lst:createSearchAlgorithms]{ código \ref{lst:createSearchAlgorithms}}, aquí podemos ver todos los algoritmos que podemos usar para aprender el modelo de series de tiempo. %este parrafo es renderizado diferente aqui que en la lap, aqui ocupa una linea menos

\lstset{language=Java, label=lst:createSearchAlgorithms, caption={[Método \texttt{createSearchAlgorithms} de la clase \texttt{TimeSeries}] Método \texttt{createSearchAlgorithms} de la clase \texttt{TimeSeries}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public void createSearchAlgorithms(){
	LinearRegression  lr= new LinearRegression();
	MultilayerPerceptron ml= new MultilayerPerceptron();
	IBk ib= new IBk();
	KStar ks= new KStar();
	LWL lw= new LWL();
	AdditiveRegression adr= new AdditiveRegression();
	Bagging ba= new Bagging();
	CVParameterSelection cv= new CVParameterSelection();
	MultiScheme ms= new MultiScheme();
	RandomCommittee rc= new RandomCommittee();
	RandomizableFilteredClassifier rf= 
		new RandomizableFilteredClassifier();
	RandomSubSpace rs= new RandomSubSpace();
	DecisionTable dt= new DecisionTable();
	M5Rules m5= new M5Rules();
	ZeroR zr= new ZeroR();
	DecisionStump ds= new DecisionStump(); //trees
	M5P m5p= new M5P();
	RandomForest rft=new RandomForest();
	RandomTree rt= new RandomTree();
	REPTree rpt= new REPTree();
	baseLearners= new Classifier[]{lr, ml, ib, ks, lw, adr,
		ba, cv, ms, rc, rf, rs, dt, m5, zr, ds, m5p, rft, rt, rpt};
}
\end{lstlisting}

Todos los algoritmos guardados en el arreglo \texttt{baseLearners} de la clase \texttt{TimeSeries} en el \hyperref[lst:createSearchAlgorithms]{ código \ref{lst:createSearchAlgorithms}}, se usan en el método \texttt{findBestConfigTimeSeries}, que aparece en el 
\hyperref[lst:findBestConfigTimeSeries]{ código \ref{lst:findBestConfigTimeSeries}} el cual construyen el modelo con cada uno de los algoritmos guardados en este arreglo, y compara los resultados de acuerdo a su error medio absoluto (MAE), imprimiendo al final el resultado de que algoritmo tuvo mejor desempeño, y una gráfica con los datos de pronostico del mejor algoritmo.
Se puede observar que el 
\hyperref[lst:findBestConfigTimeSeries]{ código \ref{lst:findBestConfigTimeSeries}} tiene líneas en común con 
el \hyperref[lst:maincustomtest]{ código \ref{lst:maincustomtest}}, en especifico de la línea 102 a la 127, ya que estas lineas se encargan de cargar los datos (102-104), especificar los campos objetivo (a pronosticar) y de tiempo (105-106), dividir el los datos en un dataset de entrenamiento y uno para pruebas (108-111), especificar la periodicidad (112-119), y crear el objeto \texttt{timeseries} que encapsula el analisis de la serie de tiempo (121-127).

\lstset{language=Java, label=lst:findBestConfigTimeSeries, caption={[Método \texttt{findBestConfigTimeSeries}] Método \texttt{findBestConfigTimeSeries}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public static void findBestConfigTimeSeries(){
try { 
	Instances datos =
		Util.instancesFromFile("SOLAR_PRODUCTION.arff");

	String targetName="kw" ;
	String xaxis="date";
	
	int numPred=24;
	int size=datos.numInstances();
	Instances train=new Instances(datos, 0, size - numPred);
	Instances test=new Instances(datos,size-numPred,numPred);
	String periodicTest=
		"day=>=*:*:*:*:*:*:*:6:*:* <=*:*:*:*:*:*:*:18:*:*";
	
	NewLagMaker lag=new NewLagMaker();
	lag.setIncludePowersOfTime(false);
	lag.setIncludeTimeLagProducts(false);
	lag.setPrimaryPeriodicFieldName("hour"); 
	lag.addCustomPeriodic(periodicTest);
	
	TimeSeries timeseries = new TimeSeries();
	timeseries.setDebug(true);
	timeseries.setTimestamp(xaxis);
	timeseries.setFieldsToForecast(targetName);
	timeseries.forecaster.setTSLagMaker(lag);
	timeseries.setHorizon(24);
	timeseries.setPrimeWindowSize(24);
	timeseries.createSearchAlgorithms();
	double mae= Double.MAX_VALUE;
	int bestBase=0;
	List<ErrorModule> preds, best=null;
	long time;

	for (int i = 0; i < timeseries.baseLearners.length; i++) {
		timeseries.reset();
		timeseries.setBaseLearner(timeseries.baseLearners[i]);
		time= System.currentTimeMillis();
		preds= timeseries.test(train, test);
		if(timeseries.getMAE() <mae){
			mae= timeseries.getMAE();
			bestBase=i;
			best= preds;
		}
		System.out.printf("%s\nMAE: %4.7f MSE: %4.7f RMSE: %4.7f"
			+" MAPE: %4.7f time %d \n", timeseries.baseLearners[i]
			.getClass().getName(),timeseries.getMAE(),timeseries.
			getMSE(),timeseries.getRMSE(),timeseries.getMAPE(),
			System.currentTimeMillis()- time);
	}
	System.out.println("Best:\n"
		+timeseries.baseLearners[bestBase].getClass().getName());
	System.out.print("MAE: "+ mae);
	JPanel gr=Util.graphSeries(best.get(0),datos,targetName,xaxis);
	JFrame jf = new JFrame("Serie de tiempo " 
		+timeseries.baseLearners[bestBase].getClass().getName());
	jf.setDefaultCloseOperation(JFrame.DISPOSE_ON_CLOSE);
	jf.setSize(800, 600);
	jf.getContentPane().setLayout(new BorderLayout());
	jf.getContentPane().add(gr, BorderLayout.CENTER);
	jf.setVisible(true);
} catch (Exception e) {
	e.printStackTrace();
}
}
\end{lstlisting}

En el for de la linea 134 se realiza la comparación de los algoritmos, primero reinicia el objeto \texttt{timeseries} en la linea 135 y en la 136 
le asigna un algoritmo encapsulado en uno de los objetos del arreglo \texttt{TimeSeries.baseLearners} de la
clase \texttt{Classifier}
del \hyperref[lst:createSearchAlgorithms]{ código \ref{lst:createSearchAlgorithms}}. La linea 137 solo sirve para poder calcular cuanto se tardo la evaluación del algoritmo (construir el modelo, extrapolar los datos y comparar los resultados con los reales) en la linea 138. El if de la linea 139-143 se encarga de guardar el mejor algoritmo y sus resultados y en la linea 144 se imprimen los resultados de la evaluación del algoritmo \texttt{i}.
Por ultimo después del for (150-160) se imprimen los resultados del mejor algoritmo y se grafican los datos en una ventana. 
En la \hyperref[fig:resultadosCompSeries]{figura \ref{fig:resultadosCompSeries}} se muestra la consola con los últimos resultados de la ejecución del \hyperref[lst:findBestConfigTimeSeries]{ código \ref{lst:findBestConfigTimeSeries}}

\begin{figure}[ht]
	\centering
	%imagen sin escalar
	\includegraphics[width=15cm]{img/resultadosComparacionSeries.png}
	\caption{Resultados de la comparación de los algoritmos de series de tiempo.}
	\label{fig:resultadosCompSeries}
\end{figure}
El programa imprimió para cada uno de los algoritmos ejecutados, información del progreso (\texttt{building forecaster...,Transforming input data..., build in 96}, etc), el nombre de la clase que encapsula el algoritmo (\texttt{weka.classifiers.trees.REPTree}), métricas de error: error medio absoluto (MAE), error medio cuadrado (MSE), raiz de error medio cuadrado (RMSE) y error porcentual medio absoluto (MAPE), y el tiempo que tardo en ejecutar la prueba. Al final se imprimió la clase con el algoritmo que tuvo el mejor desempeño y su error medio absoluto, la cual fue en este caso \texttt{weka.classifiers.lazy.IBk}.
En la \hyperref[fig:graficaResultadosCompSeries]{figura \ref{fig:graficaResultadosCompSeries}} se muestra la ventana con la gráfica de los datos del mejor algoritmo. En esta prueba se hizo una predicción a 48 horas.

\begin{figure}[ht]
	\centering
	%imagen sin escalar
	\includegraphics[width=15cm]{img/graficaResultadosCompSeries.png}
	\caption{Gráfica de los resultados de la comparación de los algoritmos de series de tiempo.}
	\label{fig:graficaResultadosCompSeries}
\end{figure}

\subsection{Redes bayesianas} \label{subsec:compRedes}
En el caso de las redes bayesianas, estas necesitan dos algoritmos base para construirse, un algoritmo que aprenda la estructura de la red, y otro que aprenda las probabilidades dentro de la estructura. Al probar los algoritmos para aprender las probabilidades surgieron errores, el estimador \texttt{BMAEstimator} no puede manejar redes con nodos con mas de un padre, y la clase \texttt{MultiNomialBMAEstimator} solo puede soportar atributos nominales binarios, así que el estimador que se uso fue el \texttt{SimpleEstimator}, aunque se dejo la estructura por si en el futuro se agrega otro algoritmo, eso se creo en el método \texttt{createEstimators} en la clase \texttt{BayesianNetwork}, el cual aparece en el 
\hyperref[lst:createLearners]{código \ref{lst:createLearners}}.
Los algoritmos para aprender la estructura de la red bayesiana se crearon en el método \texttt{createSearchAlgorithms} de la clase \texttt{BayesianNetwork}, el cual aparece en el 
\hyperref[lst:createLearners]{código \ref{lst:createLearners}}, podemos ver que ciertos algoritmos reciben parámetros, estos se declararon al principio del método, los parámetros son: 

\begin{enumerate}
	\item \texttt{markov}: Cuando se le asigna true, después de que la estructura de la red es creada se le
		aplica una corrección de manta de Markov. Esto asegura que todos los nodos en la red son parte de la
		manta de Markov del nodo objetivo (la variable que se desea predecir).
	\item \texttt{initAsNaive}: Cuando se le asigna true, la red inicial usada es una Naive Bayes (red ingenua de Bayes), la cual es una red con una flecha desde el nodo objetivo a todos los demás nodos.
	\item \texttt{maxNumPar}: El numero máximo de padres que un nodo en la red puede tener.
	\item \texttt{scoretype}: Determina el tipo de medición usada para juzgar la calidad de una estructura de
			red, esta puede ser uno de los valores: Bayes, BDeu, Minimum Description Length (MDL), Akaike 
			Information Criterion (AIC), y Entropy.
\end{enumerate}

\lstset{language=Java, label=lst:createLearners, caption={[Métodos \texttt{createEstimators} y \texttt{createSearchAlgorithms}] Métodos \texttt{createEstimators} y \texttt{createSearchAlgorithms}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
protected void createEstimators(){
	SimpleEstimator simple= new SimpleEstimator();
	estimators= new BayesNetEstimator[]{ simple/*,bma, mn*/}; 
}
protected void createSearchAlgorithms(){
	boolean markov= false, initAsNaive=false; int maxNumPar= 1;
	SelectedTag scoretype= new SelectedTag(0, 
		LocalScoreSearchAlgorithm.TAGS_SCORE_TYPE);//0-4
	file= "maxNumPar " + maxNumPar+ " initAsNaive " + initAsNaive+ 
		" markov "+markov+" scoretype " + scoretype.getSelectedTag()
		.getReadable();
	if(debug)
		System.out.println(file);
	
	GeneticSearch gs= new GeneticSearch();
	gs.setDescendantPopulationSize(100);
	gs.setPopulationSize(10);
	gs.setRuns(10);	
	gs.setMarkovBlanketClassifier(markov);
	gs.setUseCrossOver(true);
	gs.setUseMutation(true);		
	gs.setScoreType(scoretype);
	HillClimber hc=  new HillClimber();
	hc.setInitAsNaiveBayes(initAsNaive);
	hc.setMaxNrOfParents(maxNumPar);
	hc.setUseArcReversal(useArcR);
	hc.setMarkovBlanketClassifier(markov);
	hc.setScoreType(scoretype);
	K2 k2= new K2();
	k2.setInitAsNaiveBayes(initAsNaive);
	k2.setMarkovBlanketClassifier(markov);
	k2.setMaxNrOfParents(maxNumPar);
	k2.setRandomOrder(false);
	k2.setScoreType(scoretype);
	LAGDHillClimber lagd= new LAGDHillClimber();
	lagd.setInitAsNaiveBayes(initAsNaive);
	lagd.setMarkovBlanketClassifier(markov);
	lagd.setMaxNrOfParents(maxNumPar);
	lagd.setNrOfGoodOperations(5);
	lagd.setNrOfLookAheadSteps(2);
	lagd.setScoreType(scoretype);
	lagd.setUseArcReversal(useArcR);
	RepeatedHillClimber rhc= new RepeatedHillClimber();
	rhc.setInitAsNaiveBayes(initAsNaive);
	rhc.setMarkovBlanketClassifier(markov);
	rhc.setMaxNrOfParents(maxNumPar);
	rhc.setRuns(10);
	rhc.setScoreType(scoretype);
	SimulatedAnnealing sa= new SimulatedAnnealing();
	sa.setDelta(0.999);
	sa.setRuns(1000);
	sa.setMarkovBlanketClassifier(markov);
	sa.setTStart(10);
	sa.setScoreType(scoretype);
	TabuSearch tb= new TabuSearch();
	tb.setInitAsNaiveBayes(initAsNaive);
	tb.setMarkovBlanketClassifier(markov);
	tb.setMaxNrOfParents(maxNumPar);
	tb.setRuns(10);
	tb.setScoreType(scoretype);
	tb.setTabuList(5);
	TAN tan= new TAN();
	tan.setMarkovBlanketClassifier(markov);
	tan.setScoreType(scoretype);
	searches= new SearchAlgorithm[]
		{sa, gs, hc,k2, lagd, rhc, tb, tan};
}
\end{lstlisting}

Todos estos algoritmos se ponen a prueba de la misma manera que en el 
\hyperref[lst:findBestConfigTimeSeries]{código \ref{lst:findBestConfigTimeSeries}}, se corren todos uno por uno y se toma al que tiene menor error medio absoluto, la diferencia es que esta vez se ejecuto varias veces, puesto que los algoritmos toman 4 parámetros (\texttt{markov, initAsBayes, maxNumPar, scoretype}), se ejecuto una vez para cada combinación de parámetros, es decir con \texttt{markov} e \texttt{initAsBayes} en true y false, esas son 4 combinaciones, con \texttt{maxNumPar} con valores de 1 a 3, son 3 combinaciones más,y la variable \texttt{scoretype} toma 4 valores posibles, por lo que el total de combinaciones de parámetros y el numero de veces que se ejecuto este método fue de $4*3*4 = 48$. 
Un ejemplo de los resultados de estas pruebas se muestra en la 
\hyperref[fig:resultadosComparacionRed]{figura \ref{fig:resultadosComparacionRed}}, en donde los parámetros son \texttt{maxNumPar=1 initAsNaive=false markov=false scoretype=BAYES}, y el mejor algoritmo en este caso fue el \texttt{HillClimber}. 
La \hyperref[fig:GraficaResultadosCompRed]{ figura \ref{fig:GraficaResultadosCompRed}} muestra una ventana con una gráfica de los resultados de esta comparación. 
Por los resultados de la 
\hyperref[fig:resultadosCompSeries]{ figura \ref{fig:resultadosCompSeries}} y de la
\hyperref[fig:resultadosComparacionRed]{figura \ref{fig:resultadosComparacionRed}}, podemos ver que el algoritmo de series de tiempo tuvo un ligeramente mejor desempeño, ya que su MAE fue de 0.3559, mientras que el de la red bayesiana fue de 0.3872, pero esto depende mucho de la situación, ya que se hicieron varias pruebas con distintos datos y en algunos la red bayesiana daba un mejor desempeño.


\begin{figure}[ht]
	\centering
	\includegraphics[width=15cm]{img/resultadosComparacionRed.png}
	\caption{Resultados de la comparación de algoritmos de aprendizaje de redes bayesianas.}
	\label{fig:resultadosComparacionRed}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=11cm]{img/graficaResultadosCompRed.png}
	\caption{Gráfica del resultado de la comparación algoritmos de aprendizaje de redes bayesianas.}
	\label{fig:GraficaResultadosCompRed}
\end{figure}

Como ejemplo de el caso en que la red bayesiana resulta mejor que la serie de tiempo, está la 
figura \ref{fig:graficaRedBayesianaIrregluar} y \ref{fig:graficaSerieIrregluar}, 
en donde se uso un set de datos en donde un día estaba muy nublado y la producción de energía solar fue menor, esta variable climática si la tomo en cuenta de manera correcta la red bayesiana y la serie de tiempo no, dando como resultado que la red bayesiana fuera mejor con un MAE de 0.3225 usando el algoritmo de aprendizaje \texttt{weka.classifiers.bayes.net.search.local.K2} con los parámetros \texttt{maxNumPar=1 initAsNaive=false markov=false scoretype=BDeu}, en cambio la serie de tiempo tuvo un menor desempeño teniendo un error MAE mayor de 0.4437 usando el algoritmo de aprendizaje \texttt{weka.classifiers.trees.RandomForest}.

\begin{figure}[!h]
	\centering
	\includegraphics[width=11cm]{img/graficaRedBayesianaIrregluar.png}
	\caption{Gráfica del pronostico de una red bayesiana en un ambiente irregular.}
	\label{fig:graficaRedBayesianaIrregluar}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=11cm]{img/graficaSerieIrregluar.png}
	\caption{Gráfica del pronostico de una serie de tiempo en un ambiente irregular.}
	\label{fig:graficaSerieIrregluar}
\end{figure}

\subsection{Diferencias entre redes bayesianas y series de tiempo}
Con las comparaciones hechas en el algoritmo de series de tiempo se puede concluir que lo que hace es encontrar cierto patrón de repetición, y cuando se le pide que pronostique a futuro, lo que hace es repetir este patrón, tal como se ve en la figuras 
\ref{fig:graficaResultadosCompSeries} y \ref{fig:graficaSerieIrregluar}, en donde repitió el patrón casi exactamente igual; en la 
\hyperref[fig:graficaResultadosCompSeries]{ figura \ref{fig:graficaResultadosCompSeries}} se observa que acertó la predicción del primer día, pero la del segundo fue mas errado. En la 
\hyperref[fig:graficaSerieIrregluar]{ figura \ref{fig:graficaSerieIrregluar}} hizo un pronostico pobre desde el principio, y solamente lo repitió para el primero y segundo día.\\
El algoritmo de redes bayesianas puede tomar en cuenta las variables del clima, lo cual le permite hacer predicciones mas acertadas cuando el clima es un factor importante, cuando el clima no es un factor importante el algoritmo de series de tiempo tiene un desempeño parecido a la de la red bayesiana, así que en conclusión el uso de un algoritmo o de otro depende de la situación que se tenga y de la procedencia de los datos, por ejemplo, las plantas solares y eólicas dependen mucho del clima, por lo que el uso de una red bayesiana es mas apropiado para la predicción de la producción de estas, mientras que para otro tipo de clientes puede ser suficiente una serie de tiempo.

\subsection{Comparación de algoritmo bagging y red bayesiana} \label{subsec:comparacionBaggingRedB}

Después de hacer pruebas con los algoritmos de series de tiempo y redes bayesianas, se hicieron pruebas con otros algoritmos de clasificación de la librería weka, entre estos se hicieron pruebas con la clase \texttt{weka.classifiers.meta.Bagging} la cual tuvo mejores resultados que los obtenidos con los algoritmos de redes bayesianas. %poner referencia aqui
%El método bagging o ``Agregación bootstrap'' (bootstrap aggregating) se trata de un metaalgoritmo diseñado para mejorar la estabilidad y precision de algoritmos de aprendizaje automático (machine learning) usados en la clasificación estadística y regresión. 
%Esto significa que trabaja con otro algoritmo de base, mejorando su desempeño. 
Para estas pruebas se uso como algoritmo base del bagging el algoritmo de arboles de decisión encapsulado en la clase \texttt{weka.classifiers.trees.REPTree}, este es un algoritmo de clasificación como es el caso de las redes bayesianas por lo que el método bagging se comporta como un algoritmo de clasificación, esto lo hace una alternativa ideal al método de redes bayesianas.

Al tratarse de un algoritmo de clasificación, también necesita datos del clima para hacer las predicciones, así que para estas pruebas se usaron los datasets con los datos reales del clima (y no con las predicciones que da el servidor) para eliminar esa incertidumbre extra y enfocarse en que algoritmo clasifica mejor. 
Se hicieron varias pruebas con varios data sets, en la figura \ref{fig:prediccionSolarRedBayesiana} se visualiza el resultado de una de estas pruebas usando el algoritmo de red bayesiana, la cual dio un error medio absoluto de 0.2309, mientras que al probar el mismo data set con el algoritmo bagging obtuvo un error medio absoluto de 0.0762, es decir que el error se redujo a menos de la mitad, la gráfica de este resultado se puede ver en la figura \ref{fig:prediccionSolarBagging}.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/prediccionSolarRedBayesiana.png}
	\caption{Predicciones de producción solar usando red bayesiana.}
	\label{fig:prediccionSolarRedBayesiana}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/prediccionSolarBagging.png}
	\caption{Predicciones de producción solar usando algoritmo bagging.}
	\label{fig:prediccionSolarBagging}
\end{figure}

\clearpage
\section{Diseño de la arquitectura del módulo de predicción de balance} \label{sec:disArqu}

Después de hacer las pruebas de los algoritmos con los datos del agente COLDPower, se analizo en donde podría aprovecharse la predicción del consumo y producción de energía, para decidir como sería su mejor implementación; se encontró que se puede usar en: el experto de balance para saber cuantos kilowatts de \textit{up regulation} o \textit{down regulation} poner en las órdenes de balance, %aqui poner una referencia 
en el mercado al por mayor, para saber la oferta y demanda de energía aproximada que habrá en un determinado timeslot en el futuro, y en el mercado de tarifas para saber la energía consumida durante los próximos 24 timeslots y decidir si vale la pena publicar una nueva tarifa. 
Se llegó a la conclusión de que la implementación para el mercado de tarifas sería de complejidad mayor, y llevaría a que los \textit{MDP} tengan más variables a considerar y no alcanzaría el tiempo para implementarlo y probarlo antes de la competencia.
En cuanto al mercado de balance, este se desarrollo en paralelo con el módulo de predicción, así que se concluyo que tampoco alcanzaría el tiempo para implementarlo y hacer pruebas, puesto que el experto de balance necesitaría que ya estuviera listo el módulo de  predicción para empezar a hacer pruebas que arrojen resultados significativos.
Por estos motivos se decidió usar la predicción para tomar decisiones en el mercado al por mayor, el cual es un módulo que se reutilizará casi completamente de la versión pasada del broker COLDPower. Este módulo obtiene predicciones de un \textit{dataview}, el cual tiene implementado su propio método básico para hacer predicción.

\subsection{Arquitectura actual del agente COLDPower} \label{sec:arquitecturaActualAgente}

\begin{figure}[ht]
	\centering
	\includegraphics[width=16cm]{img/arquitecturaGeneral.png}
	\caption{Arquitectura general del agente COLDPower.}
	\label{fig:arquitecturaGeneral}
\end{figure}

El actual módulo de predicción básico está implementado en el \textit{dataview} (visualizador de datos)  \texttt{CustomerDataView} %poner referencia a que es un dataview
que escucha los mensajes \texttt{TariffTransaction}, los cuales contienen información del consumo o producción de cada uno de los clientes que tiene el broker, la relación entre los \textit{dataview} en general, los expertos y el servidor se muestra en la figura \ref{fig:arquitecturaGeneral}, la cual representa la arquitectura general del agente COLDPower y el servidor PowerTAC.

Los componentes de software enfocados al manejo de datos permiten abstraer al resto de los componentes del agente del manejo de mensajes del servidor y proveer información oportuna a los expertos en los mercados. Los mensajes del servidor son guardados en el \textit{data store} (almacén de datos) manteniendo la estructura de mismos. Sin embargo, los expertos no aceden directamente al
almacén de datos sino a través de los visualizadores de datos, los cuales muestran vistas de los mismos, a través de consultas predefinidas. Las vistan incluyen datos particulares, estadísticas, conjuntos ordenados, entre otros; estructuras simples que pueden ser fácilmente usadas por los expertos. Los principales componentes de software enfocados en el mercado de tarifas son el experto en tarifas de producción  el experto en tarifas de consumo \cite{Entregable4CemieEolico}. 

La funcionalidad enfocada en el mercado al por mayor tiene como principal componente al
experto de mercado al por mayor el cual se describe en la sección \ref{subsec:mercadoAlPorMayor}, este experto utiliza los datos de los \textit{data views} Customer Data View y  Wholesale Data View, para obtener la información de producción y consumo de energía, y sobre los precios del mercado al por mayor respectivamente. El visualizador de datos Customer Data View además de proveer la información del pasado sobre la producción y el consumo, también realiza una predicción simple de cual será la producción y el consumo hasta 24 horas en el futuro, para tomar en cuenta el balance (producción menos consumo) en la toma de decisiones del experto del mercado al por mayor. 
Este método de predicción sencillo para calcular el balance que habrá en una cierta hora
consiste en realizar un promedio ponderado de todos los valores guardados para esa misma hora del día, teniendo más peso los datos más recientes. Este método tiene la ventaja de ser muy sencillo y de que se ejecuta rápidamente, pero la desventaja de que es poco preciso,  y se pretende mejorar usando los algoritmos estudiados en las etapas pasadas.

\subsection{El Mercado al por Mayor} \label{subsec:mercadoAlPorMayor}
En el mercado al por mayor los agentes pueden negociar energía a través de órdenes de compra o venta para una hora determinada (hora objetivo) en cualquiera de las 24 horas anteriores. Estas órdenes pueden o no ser ejecutadas, en dependencia del precio de cruce del mercado, el cual es calculado a partir de los precios de compra y ventas de todas las órdenes recibidas por el mercado \cite{WKetterJCollinsyMdWeerdtThe2016PowerTAC}.

El experto del mercado al por mayor se enfoca en explotar la oportunidad de negocio que representa comprar energía cuando su precio se estima ser bajo y para venderla cuando se estima su precio ser alto. También tiene como objetivo obtener energía adicional necesitada por los clientes consumidores o deshacerse de la energía producida en exceso por los clientes productores y así balancear al agente evitando penalizaciones adicionales \cite{Entregable4CemieEolico}. Es importante tener en cuenta que el desbalance entre lo producido y lo consumido por los clientes de un agente, genera gastos, que en el caso de PowerTAC se reflejan como penalizaciones significativas. 

El experto del mercado al por mayor implementa los siguientes pasos para lograr sus objetivos:

\renewcommand{\labelenumi}{\arabic{enumi}$)$}

\begin{enumerate}
	\item Obtener una proyección estimada de los futuros precios de la energía y de la cantidad de energía que podría ser negociada para cada una de las 24 oportunidades asociadas a la
hora objetivo. La proyección es obtenida a partir del historial de precios de la energía y
de las cantidades de energía negociada en dicho mercado para la hora objetivo deseada.
	\item Decidir (a partir de la proyección estimada de precios de la energía), para cada una de las oportunidades asociadas a la hora objetivo si es una oportunidad de compra, de venta, o
no se negociará en la misma.
	\item Calcular el precio de la orden de compra o venta de energía para la hora objetivo (solo en caso de ser la hora actual una oportunidad de compra o venta), a partir de la proyección estimada de precios de la energía.
	\item Calcular la cantidad de energía a negociar en la hora actual, a partir de la proyección estimada de energía a negociar, de la energía de las órdenes ejecutadas y del balance estimado de energía de los clientes para la hora objetivo, esto último se saca del visualizador de datos Customer Data View con el método descrito en la sección anterior.
	\item En caso de ser la hora actual un oportunidad de compra o venta de energía, enviar la
orden al mercado por el precio y cantidad calculados.
\end{enumerate}


\subsection{Arquitectura del módulo de predicción} \label{subsection:arquitecturaModuloPred}
Tomando en cuenta la arquitectura actual del agente, para implementar el módulo de predicción lo mejor fue programar un nuevo data view, el cual se le llamo \textit{Customers Forecast Data View}, por su parecido al data view  \texttt{CustomerDataView}, con la diferencia de que implementa la predicción (forecast) con los algoritmos estudiados en el reporte pasado. La arquitectura de este nuevo visualizador de datos y su relación con los demás componentes se muestra en la figura \ref{fig:ArquitecturaModuloPrediccion}.

\begin{figure}[h]
	\centering
	\includegraphics[width=16cm]{img/ArquitecturaModuloPrediccion.png}
	\caption{Arquitectura del módulo de predicción, el data view \texttt{CustomerForecastDataView}.}
	\label{fig:ArquitecturaModuloPrediccion}
\end{figure}

En la figura \ref{fig:ArquitecturaModuloPrediccion} se han omitido las demás partes del Agente COLDPower que no se relacionan con el módulo de predicción, y se dejó solamente al almacén de datos y el experto del mercado al por mayor, que son los que tienen contacto directo con el módulo. El almacén de datos le envía mensajes al módulo de predicción, y este hace dos cosas con ellos, los procesa para cambiarlos de formato y almacenarlos en data sets agrupándolos por power type\footnote{Clientes de un tipo específico, p. ej. consumo, consumo interrumpible, producción, baterías, autos eléctricos, etc.}, y los envía al objeto \texttt{ClientClassifier}, que se encarga de hacer predicciones por cada cliente individual, sin agruparlos por power type, estos son los dos tipos de predicción que se manejan. 

La predicción agrupando por power type consiste en sumar todos los kilowatts consumidos o producidos por todos los clientes de un power type específico en un timeslot específico, almacenarlos en un solo data set y aplicar los algoritmos de predicción sobre ese data set. 
Esto tiene como ventaja que se ejecuta mucho más rápido y ocupa menos memoria que hacer la predicción por cada uno de los clientes, pero su desventaja es que depende de que los clientes suscritos sean estables, es decir, que no cancelen el contrato con el agente, o que no lleguen más clientes; cuando esto ocurre la predicción varía pues ya habrá menos o más clientes para producir la misma cantidad de energía. 
Para  intentar minimizar este efecto se dividió la cantidad de energía entre el número de clientes, dando así un estimado del consumo o producción por cliente, y al hacer la predicción sobre estos datos, como es un valor estimado de cuanto produce/consume un cliente, solo se multiplica por el número actual de clientes para tener un estimado de la producción total por power type. 
Esto daría mejores resultados si todos los clientes tuvieran patrones de consumo similares, pero debido a que algunos clientes consumen miles de veces más que otros, cuando uno de estos se suscribe (o cancela) a una tarifa, aunque solo aumente (o disminuya) en un cliente, el cociente de consumo y número de clientes cambia significativamente, este efecto se explica y ilustra mas a detalle en la sección \ref{subsection:pruebasDefaultBrokerMaxonYUDE}.

Por esta razón se decidió implementar también la predicción por cliente, la cual en vez de sumar todos los kilowatts consumidos/producidos por un cliente en cada timeslot y ponerlos en un mismo data set, guarda un data set por cada cliente y realiza una predicción por cada uno de ellos, la cual al final suma para obtener el total de energía producida/consumida esperada para un timeslot. 
Esta forma tiene la ventaja de ser más precisa, y no le afecta tanto el hecho de que se suscriban nuevos clientes o cancelen clientes actuales, pero tiene la desventaja de ser mucho más lento y ocupar más recursos. 
Es importante aclarar que los clientes de los que se hablan aquí no representan a un individuo, sino a una población de hasta 30 mil individuos, cada uno con un patrón de consumo similar, por lo que el método anterior para hacer predicciones con datos agrupados es más efectivo.
Este método está implementado en la clase \texttt{ClientClassifier}, la cual hace uso de un \textit{buffer de predicciones} el cual guarda todas las predicciones hechas hasta el momento, y al mismo tiempo corre un hilo que constantemente está produciendo nuevas predicciones y cada vez que tiene nuevos resultados los pone en el buffer, de esta manera no necesita calcular las predicciones para las próximas 24 horas en cada timeslot (como el método anterior) pues no le daría tiempo en los 5 segundos que dura un timeslot, ya que se puede llegar a tardar hasta 9 segundos. Este método se ocupa solo para los power types de consumo y consumo interrumpible, que son los que consumen más energía, aportando mas desbalance a la red.
Una vez hecha las predicciones por power type en un timeslot, se toman las predicciones disponibles del buffer de \texttt{ClientClassifier} y se da una predicción de como será el balance de los clientes del agente en las próximas 24 horas.


\section{Diseño de interfaz gráfica para representar los datos} \label{sec:disInterfaz}
Desde el reporte pasado se represento gráficamente los resultados de las diversas pruebas realizadas, esto se hizo usando la librería \texttt{org.jfree.*}, la cual es una herramienta para generar diferentes tipos de gráficos (barras, de pastel, etc.), en este proyecto se usó para representar series de tiempo usando un plano cartesiano con el eje $X$ que representa al tiempo, y el eje $Y$ que represento en su mayoría de los casos kilowatts consumidos o producidos por cierto tipo de cliente. 
Para estas primeras pruebas de rendimiento presentadas en el reporte anterior, se programó el código necesario para cada tipo de prueba por separado, y para poder realizar una nueva prueba con un archivo diferente, un algoritmo diferente, o con un dataset con un formato diferente se necesitó modificar el código fuente, esta vez lo que se pretende hacer es una interfaz gráfica desde la cual el usuario pueda seleccionar el archivo y el algoritmo a aplicar sin necesidad de modificar el código.
Para esto se diseño una interfaz que mostrara los diferentes tipos de pruebas que se pueden hacer, y que hiciera más fácil el cargar los archivos y aplicarle diferentes algoritmos a un mismo data set, y así comparar más rápidamente los algoritmos entre si.
En la figura \ref{fig:ventanaPrincipal} podemos ver el diseño de la ventana principal de la interfaz. 
\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{img/ventanaPrincipal.png}
	\caption{Ventana principal.}
	\label{fig:ventanaPrincipal}
\end{figure}

La barra de menú contiene las siguientes opciones:
\renewcommand{\labelenumi}{$\bullet$ }
\renewcommand{\labelenumii}{$\bullet$ }
\begin{enumerate}
	\item Archivo: El menú Archivo contiene opciones para cargar los datos, ya sea un solo archivo arff, o toda una carpeta llena de archivos arff que contiene los resultados de las predicciones en un juego y de los cuales se pueden sacar estadísticas.
	\item Estadísticas: Una vez cargada una carpeta con archivos arff, el menú estadísticas nos permite navegar en esos archivos y calcular el error global (el error medio absoluto de todos los archivos).
	\item Series de tiempo: El menú Series de tiempo contiene la opción de aplicar un análisis de serie de tiempo usando diferentes algoritmos base para aprender el modelo, o bien, tiene la opción de probar todos los posibles algoritmos y compararlos entre ellos, y después mostrar los resultados de cada uno, y cual fue el algoritmo que tuvo una mejor predicción. 
	\item Redes bayesianas: Contiene opciones para construir una red bayesiana con el archivo arff cargado, estas opciones son el algoritmo para aprender la estructura de la red, el \textit{score type}, o métrica a usar para definir que estructura de red bayesiana es mejor, y una opción para comparar todos los algoritmos de construcción, desplegando los resultados por algoritmo y señalando el mejor.
	\item Bagging: Al igual que los dos anteriores, el menú bagging da opciones para aplicar el análisis sobre el modelo cargado usando un algoritmo base, y también ofrece la opción de comparar estos posibles algoritmos.
\end{enumerate}


\subsection{Menú archivo} \label{subsec:menuArchivo}
El menú archivo, que aparece en la figura \ref{fig:menuArchivo} tiene tres opciones, abrir archivo .arff, abrir carpeta de estadísticas y salir.
\begin{figure}[h]%Ambiente ’figure’
	\centering
	\includegraphics[width=12cm]{img/menuArchivo.png}
	\caption{Menú archivo.}
	\label{fig:menuArchivo}
\end{figure}

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item Abrir archivo .arff: Esta opción despliega un componente \texttt{JFileChooser} con el cual el usuario seleccionará el archivo .arff a abrir. Inmediatamente después se desplegará el contenido del archivo en la ventana.
	\item Abrir carpeta de estadísticas: Ya que el broker guarda los resultados de las predicciones por timeslot, la clase \texttt{Statistics} genera muchos archivos (1300 por power type aproximadamente), uno por timeslot, y uno por cada power type o tipo de cliente, (cliente de producción, consumo, consumo interrumpible, etc), es por esto que es más fácil guardarlos en una carpeta y después abrir dicha carpeta. Al elegir esta opción carga las predicciones de todos los timeslots y grafica la primera.
	\item Sale del programa.
\end{enumerate}

\subsection{Menú estadísticas}\label{subsec:menuEstadisticas}
El menú estadísticas contiene tres opciones, calcular el error global y dos opciones para navegar entre las predicciones de los timeslots como se ve en la figura \ref{fig:menuEstadisticas}.

\renewcommand{\labelenumi}{$\bullet$ }
\begin{figure}[h]%Ambiente ’figure’
	\centering
	\includegraphics[width=12cm]{img/menuEstadisticas.png}
	\caption{Menú estadísticas.}
	\label{fig:menuEstadisticas}
\end{figure}

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item Calcular error global: Recorre todos los archivos que se encuentran en la carpeta, sumando el error absoluto de cada predicción para al final entregar el \textit{error medio absoluto} global, es decir el error medio en todos los timeslots del juego.
	\item Siguiente timeslot: Cambia la gráfica actualmente mostrada a la del siguiente timeslot.
	\item Anterior timeslot: Cambia la gráfica actualmente mostrada a la del siguiente timeslot.
\end{enumerate}

\subsection{Menú series de tiempo}\label{subsec:menuSeriesDeTiempo}
El menú series de tiempo consiste en una opción de comparar los algoritmos base, y un submenú con todos los algoritmos que se pueden usar para construir el modelo de serie de tiempo los cuales se pueden observar en la figura \ref{fig:menuSeriesDeTiempo}.

\begin{figure}[h]%Ambiente ’figure’
	\centering
	\includegraphics[width=12cm]{img/menuSerieDeTiempo.png}
	\caption{Menú series de tiempo.}
	\label{fig:menuSeriesDeTiempo}
\end{figure}
\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item Comparar algoritmos base: Usar todos los algoritmos disponibles para construir un modelo de serie de tiempo del archivo elegido, y comparar los resultados, eligiendo el que tuvo mayor precisión.
	\item Aplicar algoritmo: Elije un algoritmo en específico para construir un modelo de serie de tiempo del archivo elegido.
\end{enumerate}

\subsection{Menú redes bayesianas} \label{subsec:menuRedesBayesianas}
Este menú consta de una opción y dos submenús, la opción comparar algoritmos de construcción, y los submenús aplicar algoritmo de construcción de red tal como se ve en la figura \ref{fig:menuRedesBayesianasAlgoritmo}, y el submenú score type, que aparece en la figura \ref{fig:menuRedesBayesianasScore}.

\begin{figure}[h]%Ambiente ’figure’
	\centering
	\includegraphics[width=14cm]{img/menuRedBayesianaAlgo.png}
	\caption{Menú redes bayesianas, submenú aplicar algoritmo de construcción de red.}
	\label{fig:menuRedesBayesianasAlgoritmo}
\end{figure}

\begin{figure}[h]%Ambiente ’figure’
	\centering
	\includegraphics[width=14cm]{img/menuredBayesianaScore.png}
	\caption{Menú redes bayesianas, submenú score type.}
	\label{fig:menuRedesBayesianasScore}
\end{figure}
\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item Comparar algoritmos de construcción: Existen varios algoritmos para construir la estructura de una red bayesiana, los cuales se encuentran en el submenú \textit{Aplicar algoritmo}, esta opción construye una red bayesiana del archivo elegido con cada uno de los algoritmos disponibles, y muestra los resultados para cada una de las redes construidas, y cual fue el algoritmo que construyó el mejor modelo.
	\item Aplicar algoritmo de construcción de red: Elije un algoritmo en específico para construir la estructura de una red bayesiana a partir de los datos del archivo arff que el usuario selecciono.
	\item Score type: El tipo de métrica a tomar en cuenta para decidir que estructura es mejor.
\end{enumerate}

\subsection{Menú bagging} \label{subsec:menuBagging}
Al igual que los últimos dos, el menú Bagging contiene una opción para comparar los algoritmos base que este clasificador recibe, y contiene una opción para seleccionar un algoritmo base específico a aplicar, este menú se muestra en la figura \ref{fig:menuBagging}.

\begin{figure}[ht]%Ambiente ’figure’
	\centering
	\includegraphics[width=14cm]{img/menuBagging.png}
	\caption{Menú bagging.}
	\label{fig:menuBagging}
\end{figure}

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item Comparar algoritmos base del bagging: opción para comparar los algoritmos base que se pueden usar con el método bagging, probando cada uno de estos construyendo un modelo del archivo elegido por el usuario, y muestra los resultados de cada modelo construido, señalando el mejor.
	\item Aplicar algoritmo base: Elije un algoritmo base a usar con el método bagging.
\end{enumerate}


\section{Implementación del módulo de pronóstico en una API} \label{sec:implementacionAPI}

Para facilitar la integración de la nueva funcionalidad de predicción al agente, se pusieron las clases más importantes implementadas hasta el momento en un paquete, y se agregaron clases para implementar el  \textit{patrón de diseño Factory} formando una API y así facilitar la integración con el agente, las siguientes fueron las clases agregadas al paquete: 

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item \texttt{BayesianNetwork}: Clase que encapsula la construcción de un modelo de red bayesiana a partir de un data set, internamente hace el filtrado de los datos, que consiste en convertir los campos de tipo numérico a tipo nominal\footnote{En el contexto de la librería weka, un dato nominal es una variable discreta, con posibles valores específicos, y un dato numérico es una variable que puede tomar cualquier valor real.} dividiendo los posibles valores en rangos. Utiliza la clase \texttt{weka.classifiers.bayes.BayesNet} para crear el modelo una vez teniendo los datos filtrados. La clase hereda de la clase \texttt{AbstractClassifier} para implementar los métodos \texttt{buildClassifier} y \texttt{classifyInstance} así que se puede usar como una clase \texttt{Classifier} de weka normal, lo cual se aprovecha en la clase \texttt{RegressionFactory} en la sección \ref{subsec:claseRegressionFactory}.
	
	\item \texttt{TimeSeries}: El algoritmo para análisis y predicción en series de tiempo se encuentra encapsulado en la clase \texttt{TimeSeries}, usando la clase \texttt{WekaForecaster} que se encuentra como una extensión de la libreria weka en el paquete \texttt{weka.classifiers.timeseries} como analizador de series de tiempo, junto con métodos para hacer pruebas y calcular el error de las predicciones hechas. La clase \texttt{TimeSeries} también hereda de \texttt{AbstractClassifier} para poder tomarse como un método de regresión genérico y poder usarse con el patrón de diseño Factory. %agregar al marco teorico
	
	\item \texttt{NewLagMaker}: La clase \texttt{weka.classifiers.timeseries.WekaForecaster} utilizada en la clase \texttt{TimeSeries} funciona creando variables de arrastre (lag variables) que modelan el data set como una serie de tiempo, la clase encargada de esto es \texttt{TSLagMaker} dentro del paquete \texttt{weka.classifiers.timeseries.core}, pero debido a que se encontraron algunos problemas con esta, se hizo la clase \texttt{NewLagMaker} a partir de esta, para corregir ciertos errores y adaptarla a la API.
	
	\item \texttt{Util}: La clase \texttt{Util} contiene distintos métodos que son comunes a lo largo de las otras clases de la API, tales como leer un archivo arff (extensión de los data set de weka) o escribir en uno, crear los datasets usados para almacenar los datos de producción y consumo (especificando sus variables y tipos de datos), crear una sola instancia de un data set, entre otros.
	
	\item \texttt{BayesNetFactory}: Esta clase encapsula la decisión de como se crean los objetos de la clase \texttt{BayesianNetwork} según el power type que vaya a pronosticar. La implementación de esta clase se detalla en la sección \ref{subsec:claseBayesNetFactory}.
	
	\item \texttt{TimeSeriesFactory}: Esta clase encapsula la creación y configuración del objeto \\\texttt{TimeSeries} según su power type y el tamaño del dataset, ya que los clientes de cada power type se comportan diferente y la predicción resulta mejor con diferentes configuraciones.
	
	\item \texttt{RegressionFactory}: Esta clase decide qué algoritmo se usará para cada power type, usando las clases \texttt{BayesNetFactory} y \texttt{TimeSeriesFactory} para crear los objetos de la clase \texttt{weka.classifiers.Classifier} que encapsulan los métodos de predicción.
\end{enumerate} %puede ser util poner un diagrama de uml de estas clases pero no da tiempo D:

\subsection{Clase \texttt{BayesNetFactory}} \label{subsec:claseBayesNetFactory}
La clase \texttt{BayesianNetwork} tiene dos maneras de construir la estructura de una red bayesiana, la primera es usando uno de los algoritmos de construcción vistos en el segundo reporte, la otra es cargándolo desde un archivo. Después de hacer varias pruebas con los algoritmos de construcción, se observó que los mejores modelos tardaban en construirse, así que se decidió aprovechar y guardar la estructura construida en un archivo para no tener que volver a construirla y perder valioso tiempo de ejecución al hacerlo. La clase \texttt{BayesNetFactory} fue pensada para crear los objetos \texttt{BayesianNetwork} con la estructura ya cargada según su power type (ya que los clientes de cada power type tienen un comportamiento diferente). Las pruebas que se hicieron arrojaron que el power type que mejor se puede predecir con una red bayesiana fue el de producción solar, por lo cual se guardó esta estructura para ser cargada después.
La implementación de la clase \texttt{BayesianNetwork} se muestra en el código \ref{lst:claseBayesNetFactory}.

\lstset{language=Java, label=lst:claseBayesNetFactory, caption={[Clase \texttt{BayesNetFactory}] Clase \texttt{BayesNetFactory}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public class BayesNetFactory {
	public static BayesianNetwork buildFactory(PowerType pt){
		BayesianNetwork bn=null;
		String path="src/main/resources/config/"+
			"bayes_net_structures/";
		if(pt.equals(PowerType.SOLAR_PRODUCTION)){
			bn= new BayesianNetwork();
			bn.loadStructureFromFile(path+
				"Structure_SOLAR_PRODUCTION");
		}else{
			bn= new BayesianNetwork(); 
			bn.maxNumPar=3;
			bn.initAsNaive=true;
			bn.markov=false;
			bn.setScoreType(1);
		}
		return bn;
	}
}
\end{lstlisting}
Cuando el power type no es del tipo producción solar, se deja configurada la red para que aprenda la estructura usando un algoritmo que corre en un tiempo suficientemente rápido para correr en un timeslot. Debido a que en las últimas pruebas realizadas el algoritmo Bagging superó en precisión al de red bayesiana, este lo sustituyó en la clase \texttt{RegressionFactory}, estas pruebas se describen en la sección \ref{subsec:comparacionBaggingRedB}.

\subsection{Clase \texttt{TimeSeriesFactory}} \label{subsec:claseTimeSeriesFactory}
La clase \texttt{TimeSeriesFactory} realiza la configuración del objeto \texttt{TimeSeries} que se va a usar para predicción según el power type y el tamaño del data set. Cuando se trabaja con el power type de consumo, es conveniente especificar que hay un periodo cíclico entre las 6 de la mañana y las 6 de la tarde, con un algoritmo base \texttt{weka.classifiers.meta. RandomCommittee}, mientras que cuando se trabaja con el power type de consumo interrumpible, cuando el data set es pequeño (menos de 165 instancias) le conviene usar el algoritmo base \texttt{RandomCommittee}, y si es mayor el algoritmo \texttt{weka.classifiers.rules.DecisionTable}. La implementación puede verse en el código \ref{lst:claseTimeSeriesFactory}.


\lstset{language=Java, label=lst:claseTimeSeriesFactory, caption={[Clase \texttt{TimeSeriesFactory}] Clase \texttt{TimeSeriesFactory}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public class TimeSeriesFactory {
	public static TimeSeries buildFactory(PowerType pt, 
			int dsSize, String xaxis, String targetName){
		NewLagMaker lag=new NewLagMaker();
		lag.setIncludePowersOfTime(false);
		lag.setIncludeTimeLagProducts(false);
		lag.setPrimaryPeriodicFieldName("hour"); 
		CustomPeriodicTest period= new CustomPeriodicTest(
			">=*:*:*:*:*:*:*:*:*:* <=*:*:*:*:*:*:*:*:*:*");
		TimeSeries timeseries = new TimeSeries();
		timeseries.setDebug(false);
		timeseries.setTimestamp(xaxis);
		timeseries.setFieldsToForecast(targetName);
        timeseries.setHorizon(24);
        timeseries.setPrimeWindowSize(24);
        lag.setAddWeekendIndicator(true);
        String periodicTest;
		if(pt.equals(PowerType.CONSUMPTION)){
			period.getLowerTest().setOperator(">=");
			period.getLowerTest().setHourOfDay("6");
			period.getUpperTest().setOperator("<=");
			period.getUpperTest().setHourOfDay("18");
	        timeseries.setBaseLearner(new RandomCommittee());
		} else if(pt.equals(PowerType.INTERRUPTIBLE_CONSUMPTION)){
			if(datasetSize<165){
				timeseries.setBaseLearner(new RandomCommittee());
			}else{
				timeseries.setBaseLearner(new DecisionTable());
			}
		}else{
			timeseries.setBaseLearner(new LinearRegression());
		}
		periodicTest="day="+ period.toString()+"";
		lag.addCustomPeriodic(periodicTest);
		timeseries.forecaster.setTSLagMaker(lag);
		return timeseries;
	}
}

\end{lstlisting}

\clearpage 
\subsection{Clase \texttt{RegressionFactory}} \label{subsec:claseRegressionFactory}
La clase \texttt{RegressionFactory} crea y devuelve el objeto que encapsula el algoritmo de regresión que mejor funcione para el power type dado y el tamaño del data set. Para el power type solar lo mejor es usar el método Bagging con el algoritmo base \texttt{weka.classifiers.trees. REPTree}, si el power type es de tipo consumo o consumo interrumpible lo mejor es usar análisis de series de tiempo, si es de producción eólica también es conveniente usar el método Bagging, y si es de otro tipo, en general es buena idea usar una serie de tiempo.
En el código \ref{lst:claseRegressionFactory} se encuentra la implementación de esta clase.

\lstset{language=Java, label=lst:claseRegressionFactory, caption={[Clase \texttt{RegressionFactory}] Clase \texttt{RegressionFactory}},
tabsize=3 ,numbers=left,  stepnumber=1, firstnumber=100}

\begin{lstlisting}[frame=single]  
public class RegressionFactory {
	public static final PowerType powerTypes[]= new PowerType[]{
		PowerType.BATTERY_STORAGE, PowerType.ELECTRIC_VEHICLE,
		PowerType.CONSUMPTION,PowerType.INTERRUPTIBLE_CONSUMPTION, 
		PowerType.PRODUCTION, PowerType.PUMPED_STORAGE_PRODUCTION, 
		PowerType.RUN_OF_RIVER_PRODUCTION,PowerType.SOLAR_PRODUCTION, 
		PowerType.STORAGE, PowerType.THERMAL_STORAGE_CONSUMPTION, 
		PowerType.WIND_PRODUCTION, PowerType.FOSSIL_PRODUCTION, 
		PowerType.CHP_PRODUCTION};
	
	private static HashMap<PowerType, Integer> indexs;
	private static int lastTS;
	
	private static Classifier classifiers[];
	
	public static  Classifier getRegressionAlgorithm(PowerType pt, 
			int dsSize, int timeslot){
		Classifier cl= null;
		if(indexs==null){
			buildIndex(dsSize);
		}
		if(!ClientClassifier.isPowertypeSupported(pt)){
			if(timeslot==lastTS){ 
				if(classifiers[indexs.get(pt)]!=null)
					return classifiers[indexs.get(pt)];
			}else{
				if(timeslot<lastTS){
					return null;
				}
				Arrays.fill(classifiers, null);
				lastTS=Math.max(timeslot, lastTS);
			}
		}
		if(pt==PowerType.SOLAR_PRODUCTION){
			Bagging bg = new Bagging();
	    	bg.setClassifier(new REPTree());
	    	cl = bg;
		} else if(pt== PowerType.CONSUMPTION 
				|| pt==PowerType.INTERRUPTIBLE_CONSUMPTION){
			cl=TimeSeriesFactory.buildFactory(pt,dsSize,"date","kw");
		} else if(pt== PowerType.WIND_PRODUCTION){
			Bagging bg = new Bagging();  
	    	bg.setClassifier(new REPTree());
	    	cl =bg;
		}else{
			cl=TimeSeriesFactory.buildFactory(pt,dsSize,"date","kw");
		}
		return classifiers[indexs.get(pt)]=cl;
	}
	public static boolean isBuilt(PowerType pt, int dsSize, 
			int timeslot){
		return lastTS==timeslot && classifiers[indexs.get(pt)]!=null 
				&& !ClientClassifier.isPowertypeSupported(pt); 
	}
	private static void buildIndex(int dsSize) {
		lastTS=dsSize-1;
		indexs= new HashMap<>();
		for (int i = 0; i < powerTypes.length-1; i++) {
			indexs.put(powerTypes[i], i);
		}
		indexs.put(PowerType.CHP_PRODUCTION, 11);
		classifiers= new Classifier[powerTypes.length];
	}
}	
\end{lstlisting}
además de decidir que algoritmo retornar según el power type, la clase \texttt{RegressionFactory} también se encarga de construir solamente una instancia por cada timeslot, ya que cada timeslot, se mandan a llamar los métodos de pronóstico 24 veces, uno por cada hora en el futuro. Esto se hace para que el modelo solo sea construido una vez por timeslot, excepto cuando el encargado de pronosticar ese timeslot sea la clase \texttt{ClientClassifier}, esto se corrobora en la línea 121 del código \ref{lst:claseRegressionFactory}, llamando al método \texttt{isPowertypeSupported(pt)} de la misma clase \texttt{ClientClassifier} el cual regresa true cuando el power type que se requiere predecir es responsabilidad de esta clase.

El construir el modelo una sola vez por timeslot se logra guardándolos en el arreglo de objetos \texttt{Classifier} en la línea 113. Cada elemento del arreglo guarda un objeto que encapsula el método de regresión\footnote{En weka los algoritmos de regresión y clasificación son implementados por igual en una subclase de la clase \texttt{classifier}, aunque el algoritmo no sea un clasificador} para un power type, el \texttt{HashMap indexs} guarda los indices que representan donde guardar los objetos \texttt{Classifier} en el arreglo \texttt{classifiers} según su power type, así que se usa para acceder al arreglo como se ve en las lineas 123, 124, 147 y 151. En el método \texttt{buildIndex} de la línea 154 vemos como se construye este indice.

El método \texttt{isBuilt} sirve para saber si el objeto \texttt{Classifier} que se devuelve ya construyó el modelo o no, y así no construirlo dos veces.

\section{Integración de la API con el agente COLDPower} \label{sec:integracionAPI}

Para integrar el módulo de predicción  % metodos de prediccion?
se copió el paquete que fungirá como API en el proyecto del agente COLDPower, añadiendo algunas clases necesarias para la integración, clases tales como:

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item \texttt{ClientClassifier}: Administra los datos de cada uno de los clientes, quiénes están presentes, quiénes se salen y quiénes llegan (con el hash map \texttt{clientesActivos}), además guarda el buffer de los resultados de las predicciones por cliente, este contiene las predicciones hechas por cliente individual por la clase \texttt{ForecasHandler} de las próximas 120 horas (ya que no se actualizan cada timeslot, necesita un buffer de más de 24 horas, suficientes para que no se le acabe el tiempo en lo que la clase \texttt{ForecasHandler} hace la siguientes predicciones.
	
	\item \texttt{ClientData}: Contiene los datos de un modelo de cliente individual, cada que llega información de producción/consumo nueva de un cliente, la clase \texttt{ClientClassifier} le pasa los datos al objeto \texttt{ClientData} correspondiente mediante el método \texttt{addData}, y este después recibe la información del clima de la clase \texttt{ForecastHandler} (la cual la obtuvo de \texttt{CustomersForecastDataView}) a través del método \texttt{addInstances}, cada vez que el hilo de \texttt{ForecastHandler} termina de hacer una predicción, antes de empezar la siguiente, para juntarla con los datos de producción/consumo y anexarla al data set interno de la clase \texttt{weka.core.Instances}, el cual la clase \texttt{ForecastHandler} usa para hacer las predicciones.
La razón por la cual primero obtiene los datos de producción/consumo y luego los del clima, es para mantener sincronizada la comunicación, ya que los mensajes de producción/consumo son varios por timeslot y si se agregan al objeto \texttt{ClientData.instances} usado por la clase \texttt{ForecastHandler} puede ser que este los este usando en ese momento. Para evitar esto la clase \texttt{ClientData} los va guardando en una cola ({\tt\lstinline$Queue<DataTimeslot> data$ }  en la figura \ref{fig:clasesAPI}), y cuando la clase \texttt{ForecastHandler} empieza otra predicción, este junta los datos del clima con los datos de producción/consumo de la cola, para agregarlo al objeto \texttt{ClientData.instances}.
	
	\item \texttt{ForecastHandler}: Esta clase se encarga de hacer las predicciones por cliente individual y guardarlas en un buffer en la clase \texttt{ClientClassifier}. Ya que la predicción se demora de 3 a 9 segundos en función del tamaño del data set (cada timeslot crece más por lo que cada vez se tarda más), esta se realiza en un hilo diferente al de los demás para no entorpecer la ejecución de todo el agente. Este toma la información de las instancias \texttt{ClientData} y pone los resultados en el buffer de \texttt{ClientClassifier} cada vez que tiene nuevas predicciones.
	
	\item \texttt{LoadBootstrap}: El servidor PowerTAC primero simula algo que llama ``periodo bootstrap'' el cual es una simulación de dos semanas (336 timeslots) en donde el único broker activo es el default broker que tiene el servidor, esto con el objetivo de recabar los datos sobre la producción y el consumo de los clientes, para después enviárselos a cada uno de los agentes en mensajes de tipo \texttt{CustomerBootstrapData} y que estos puedan tomar decisiones, esta clase recibe esos mensajes y los guarda en los objetos \texttt{ClientData}.
\end{enumerate}

Todas estas clases serán usadas por el data view
\texttt{CustomersForecastDataView} directa o indirectamente,
 en el diagrama \ref{fig:clasesAPI} se muestra la relación entre estas clases.

La clase \texttt{CustomersForecastDataView} contiene el objeto \texttt{HashMap<String, ClientData> clientes}, que es un Hash map donde la llave es el nombre del cliente, y el valor guardado es la información de dicho cliente, este objeto es único y se comparte entre las clases \texttt{ClientClassifier}, \texttt{ForecastHandler} y \texttt{LoadBootstrap}, es por eso que la clase \texttt{ClientData} tiene una relación de agregación con estas tres clases como se ve en el diagrama \ref{fig:clasesAPI}, ya que cada una hace uso de esta clase. Es por medio de este objeto que la clase \texttt{ClientClassifier} le comparte la información sobre los clientes a la clase \texttt{ForecastHandler}, y cada que esta termina de llenar su buffer interno de predicciones, se lo pasa a la clase \texttt{ClientClassifier} usando el método \texttt{setBuffer}, y para mandar a llamarlo necesita tener la instancia de la clase \texttt{ClientClassifier}, por lo que una relación de agregación existe entre ellas; la clase \texttt{ClientClassifier} forma parte de la clase \texttt{ForecastHandler}.


\begin{figure}[ht]%https://www.seas.es/blog/informatica/agregacion-vs-composicion-en-diagramas-de-clases-uml/
	\centering
	\includegraphics[width=15cm]{img/DiagramaUMLClasesAPI.png}
	\caption{Diagrama UML de las clases en la API de predicción.}
	\label{fig:clasesAPI}
\end{figure}

\subsection{La clase CustomersForecastDataView}

El data view \texttt{CustomersForecastDataView} se basa en la clase \texttt{CustomerDataView}, la cual recibe los mensajes de transacciones de tarifas y da predicciones de balance, solo que la clase \texttt{CustomersForecastDataView} usa los métodos de machine learning estudiados en este proyecto (y detallados en reportes anteriores)para dar las predicciones de balance, y no un promedio ponderado como en el caso de la anterior clase \texttt{CustomerDataView}. Como esta nueva clase necesita datos sobre el clima, ademas de escuchar los mensajes de transacciones de tarifas, también escucha los mensajes del reporte del clima (como se encuentra el clima en ese momento) y de predicción del clima. Estos diferentes tipos de mensajes se encapsulan en sus respectivas clases y son enviados al objeto \texttt{CustomersForecastDataView}, en la figura \ref{fig:UMLCustomerForecastDataview} se muestran los diagramas UML de la clase \texttt{CustomersForecastDataView} y las clases que contienen los mensajes de transacciones de tarifas y el reporte y predicción del clima.

Los mensajes de transacciones de tarifas son encapsulados en la clase \texttt{TariffTransaction}, esta contiene la información acerca del tipo de transacción que se realiza en el atributo \texttt{txType} de tipo Type, este es un enum con los posibles valores:  \texttt{Type \{PUBLISH, PRODUCE, CONSUME, PERIODIC, SIGNUP, WITHDRAW, REVOKE\}}, aunque la clase solo toma en cuenta los mensajes de tipo \texttt{PRODUCE, CONSUME, SIGNUP} y \texttt{WITHDRAW}, y los demás los ignora.
\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item \texttt{PRODUCE}: Significa que el objeto \texttt{TariffTransaction} guarda información sobre la compra de energía producida a un cliente productor o conjunto de clientes, por lo cual el atributo \texttt{kw} es positivo y el atributo \texttt{charge} es negativo, lo cual significa que el agente le paga al cliente. Para saber mas sobre el o los cliente se puede consultar el objeto \texttt{CustomerInfo} retornado por el método \texttt{getCustomerInfo} el cual contiene su nombre, power type, población, y otros atributos que no se usan en esta competencia. Recordemos que los clientes en el servidor son agrupados por tipo, por lo que un cliente puede representar una población de clientes del mismo tipo (un edificio de oficinas por ejemplo tiene varios clientes los cuales se pueden agrupar), la información de este conjunto de clientes esta en este objeto, y para saber la población o numero de clientes agrupados, se puede consultar el método \texttt{getCustomerCount}.
	
	 \item \texttt{CONSUME}: Cuando una transacción de tarifa es de este tipo, significa que hubo una venta de energía a un cliente o clientes consumidores,  por lo que el atributo \texttt{kw} es negativo y el atributo \texttt{charge} es positivo, lo cual significa que el cliente le paga al agente.
	
	\item \texttt{SIGNUP}: Las transacciones de este tipo indican que un cliente o clientes se han suscrito a una tarifa, el atributo \texttt{kw}	 es 0 puesto que se acaba de suscribir, y el atributo \texttt{charge} puede ser positivo o negativo, dependiendo de la tarifa, este tipo de mensaje se usa para actualizar el hash map \texttt{clientesActivos} que contiene los clientes activos en la clase \texttt{ClientClassifier}, que luego se usa en el método \texttt{getActiveClients} tal como se ve en la figura \ref{fig:clasesAPI}, este ultimo método se usa para saber de que clientes predecir el consumo en la clase \texttt{ForecastHandler}, por lo que la clase \texttt{CustomersForecastDataView} le pide a la clase \texttt{ClientClassifier} una lista con los clientes activos, y le envía esta lista al objeto \texttt{ForecastHandler} tal como se ve en el diagrama de secuencia de la figura \ref{fig:diagramaDeSecuencia}.
	
	\item \texttt{WITHDRAW}: Las transacciones de este tipo indican que un cliente o clientes se han retirado de la tarifa, por lo que ya no son clientes a partir de ese momento (hasta que se vuelvan a suscribir), el atributo \texttt{kw} es de 0 y el \texttt{charge} puede ser positivo si la tarifa especifico un ``early withdraw penalty'', esto es un pago por abandonar la tarifa antes de que se cumpla el plazo mínimo \cite{WKetterJCollinsyMdWeerdtThe2017PowerTAC}. Este tipo de mensajes también se usan para actualizar el registro de los clientes activos guardados en el hash map%ponerlo en el marco teorico ?
	 \texttt{ClientClassifier.clientesActivos}, al llegar uno de estos mensajes el cliente se saca de este hash map, o se actualiza el valor asociado a la clave del hash map (la clave es el nombre del cliente), un entero que representa la población actual de ese cliente.
\end{enumerate}

\begin{figure}[h]
	\centering
	\includegraphics[width=15cm]{img/UMLCustomerForecastDataview.png}
	\caption{Diagrama UML de la clase \texttt{CustomersForecastDataView}}
	\label{fig:UMLCustomerForecastDataview}
\end{figure}

Las clases \texttt{WeatherReport} y \texttt{WeatherForecast} contienen el estado del clima en el timeslot actual y el reporte del clima para las próximas 24 horas respectivamente, estos datos son: la temperatura, velocidad del viento, dirección del viento y nubosidad.
Estos tres tipos de mensajes son enviados al data view \texttt{CustomersForecastDataView} mediante el método \texttt{put(String feature, Object msg)}, el cual decide a que otro método pasar el mensaje con base en el parámetro \texttt{feature}, el cual describe si el objeto es un \texttt{TariffTransaction}, \texttt{weatherReport} o \texttt{WeatherForecast}, y con esto se decide enviar al método \texttt{put(TariffTransaction msg), putWeather(WeatherReport msg)} o \texttt{putWeatherForecast(WeatherForecast msg)} (véase figura \ref{fig:UMLCustomerForecastDataview}).

El método \texttt{getBalance(Timeslot toForecast)} de la clase \texttt{CustomersForecastDataView} es el encargado de hacer la predicción y es el que manda a llamar el experto del mercado al por mayor, este calcula el balance esperado para el timeslot \texttt{toForecast}, el balance es los kilowatts producidos menos los kilowatts consumidos por sus clientes, para calcular esto se llama respectivamente a los métodos de dicha clase \texttt{getProductionKWhsForecast} y \\ \texttt{getConsumptionKWhsForecast}, estos métodos calculan la producción o consumo calculando las dos maneras de hacer predicción, por power type o por cliente, como se describió en la sección \ref{subsection:arquitecturaModuloPred}, las predicciones por cliente, estas se piden al objeto \texttt{ClientClassifier} mediante el método \texttt{getPredictionsByClients}, este método retorna la predicción guardada en el buffer, el cual se actualiza cada cierto tiempo por el hilo que corre la clase \texttt{ForecastHandler}, es por eso que los mensajes a la clase \texttt{ForecastHandler} se representan en el diagrama de secuencia de la figura \ref{fig:diagramaDeSecuencia} como asíncronos, este día grama representa todo este proceso.
Este hilo que corre en la clase \texttt{ForecastHandler} se actualiza con nuevos datos de dos maneras, la información sobre el consumo de los clientes la toma cada que la necesita del objeto \texttt{HashMap<String,ClientData> clientes}, este objeto a su vez es actualizado cada timeslot por el objeto \texttt{ClientClassifier} el cual le pasa datos sobre el balance (kilowatts de producción y consumo) como se ve en la figura \ref{fig:diagramaDeSecuencia}, 
 y como la clase \texttt{ClientData} esta sincronizada (como se explica en la sección \ref{sec:integracionAPI}) no hay ningún problema con que la clase \texttt{ClientClassifier} y \texttt{ForecastHandler} accedan al mismo tiempo a los objetos del hash map \texttt{clientes}.
La otra manera en que se actualiza el hilo es por los mensajes que le llegan del data view \texttt{CustomersForecastDataView} cada timeslot, el cual le pasa una lista con los nombres de los clientes, datos del clima mediante un objeto \texttt{Instances} (que contiene los datos mostrados en la figura \ref{fig:archivoAbierto}, la cual es una representación de texto del objeto \texttt{Instances}) y el id del timeslot actual, mediante la función \texttt{generate} descrita en el diagrama UML de la figura \ref{fig:clasesAPI}.

\begin{figure}[h]
	\centering
	\includegraphics[width=17.5cm]{img/diagramaDeSecuencia.png}
	\caption{Diagrama de secuencia de la clase \texttt{CustomersForecastDataView} y asociadas.}
	\label{fig:diagramaDeSecuencia}
\end{figure}


\section{Implementación de la interfaz gráfica} \label{sec:implementacionInterfazGraf}

La interfaz se implemento usando el patrón de diseño  \textit{modelo vista controlador}, para separar la funcionalidad de la vista, en la figura \ref{fig:estructuraAPI} se puede ver las estructuras de los paquetes usada para crear la interfaz.
Esta estructura está dividida en 4 paquetes, un paquete para las clases pertenecientes al modelo, otro para las clases pertenecientes a la vista, otro para las clases controladoras. Estos cuatro paquetes se encuentra dentro de  \texttt{org.manuel.examples.RegressionAndClassificationExamples}, el paquete \texttt{weka} contiene las clases que encapsulan el modelo, es decir, los algoritmos usados para las pruebas, el paquete \texttt{vistas} contiene las clases que se encargan de mostrar los datos en ventanas, y el paquete \texttt{controladores}, contiene las clases \textit{``controladoras''}, es decir, las encargadas de gestionar la comunicación del usuario y el modelo a través de la interfaz, respondiendo a los eventos generados por el usuario. Por último la clase \texttt{App} contenida también en el paquete \texttt{org.manuel.examples.RegressionAndClassificationExamples} contiene el \texttt{main}, el cual solo lanza la interfaz. 

\begin{figure}[ht]%Ambiente ’figure’
	\centering
	\includegraphics[width=15cm]{img/paquetesInterfaz.png}
	\caption{Estructura de paquetes de la interfaz gráfica.}
	\label{fig:estructuraAPI}
\end{figure}

Las clases pertenecientes al \texttt{modelo}, pertenecientes al paquete \texttt{weka} son:

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item \texttt{BayesianNetwork}: Clase que encapsula los algoritmos de redes bayesianas, como se explicó en la sección \ref{sec:implementacionAPI}, también contiene un arreglo de objetos que encapsulan todos los algoritmos de aprendizaje de  la estructura de una red bayesiana (mostrados en la figura \ref{fig:menuRedesBayesianasAlgoritmo}) usado para la funcionalidad de comparar algoritmos de construcción.
	
	\item \texttt{LinearRegression}: Clase usada en las primeras actividades para comprender el funcionamiento de la librería weka, encapsula el algoritmo de regresión lineal.
	
	\item \texttt{NewLagMaker}: Clase encargada de generar las variables de arrastre de los data sets usados por la clase \texttt{TimeSeriesFactory} como se explicó en la sección \ref{sec:implementacionAPI}.
	
	\item \texttt{PolynomialRegression}: Clase usada en las primeras actividades para extender el funcionamiento de la clase \texttt{LinearRegression} para hacer regresión polinomial, usando variables de arrastre generadas a partir del modelo original. Esto permitió comprender la importancia de las variables de arrastre. %poner referencia al la parte donde se habla de esta clase.
	
	\item \texttt{TimeSeries}: Clase que encapsula métodos para el análisis de series de tiempo como se explicó en la sección \ref{sec:implementacionAPI}.
	
	\item \texttt{Util}: La clase \texttt{Util} contiene los mismos métodos explicados en la sección \ref{sec:implementacionAPI}, además de métodos para graficar los resultados de los algoritmos (metodos no usados en la API).	
\end{enumerate}

Las clases pertenecientes a la \textit{vista}, pertenecientes al paquete \texttt{vistas} son:

\renewcommand{\labelenumi}{$\bullet$ }
\begin{enumerate}
	\item \texttt{Ventana}: Esta clase se encarga de construir la ventana que se muestra en la figura \ref{fig:ventanaPrincipal}, construyendo sus menús y sirviendo como contenedor para mostrar los resultados de los algoritmos.
	
	\item \texttt{VentanaParametros}: Esta clase muestra el formulario al usuario que aparece en la figura \ref{fig:VentanaParametros} para que este especifique algunos parámetros antes de correr un algoritmo, los cuales son:
	
	 \begin{enumerate}
	 	\item Instancias de pruebas: cuando un algoritmo de regresión se ejecuta y se desea medir su precisión, se necesita dividir el data set seleccionado en dos partes, una parte (la más grande) es usada para entrenamiento del modelo y la otra es usada para probar la precisión del modelo generado por el algoritmo y así cuantificar que tan bueno es este. Este campo le especifica cuantas instancias se usarán para hacer pruebas.

	 	\item Variable objetivo: Especifica que variable del data set se va a predecir.

	 	\item Variable de tiempo: Especifica que variable del data set modela el tiempo, por lo general es una fecha, pero también puede ser de tipo numérico, y esta es usada como eje $X$ al momento de graficar los resultados.
	 \end{enumerate} 

\end{enumerate}

\begin{figure}[ht]
	\centering
	\includegraphics[width=10cm]{img/VentanaParametros.png}
	\caption{Formulario creado por la clase \texttt{VentanaParametros}.}
	\label{fig:VentanaParametros}
\end{figure}

\subsection{Aplicar un algoritmo a un data set}
El menú archivo permite abrir archivos de dos formas diferentes: un data set individual (archivos con extensión arff), y un conjunto de data sets que contienen las estadísticas de un juego (toda una carpeta). Los algoritmos contenidos en los menús \texttt{Series de tiempo, Redes bayesianas} y \texttt{Bagging}, trabajan con la primera opción, un solo data set el cual se selecciona con la opción \texttt{Abrir archivo .arff} del menú archivo el cual se muestra en la figura \ref{fig:menuArchivo}, en la figura \ref{fig:seleccionArchivo} se muestra la ventana que sale al elegir esta opción.

\begin{figure}[ht]
	\centering
	\includegraphics[width=10cm]{img/seleccionArchivo.png}
	\caption{Selección de archivo arff.}
	\label{fig:seleccionArchivo}
\end{figure}

Al seleccionar el dataset (archivo arff), inmediatamente se muestra su contenido en la ventana principal de la interfaz, mostrándolo como solo lectura. Podemos ver el aspecto de la ventana con el archivo abierto en la figura \ref{fig:archivoAbierto}. 
\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{img/archivoAbierto.png}
	\caption{Interfaz después de abrir un archivo arff}
	\label{fig:archivoAbierto}
\end{figure}

En este momento se encuentra listo para que se le aplique alguno de los algoritmos de los menús \texttt{Series de tiempo, Redes bayesianas} o \texttt{Bagging}, todos estos tienen la misma manera de mostrarse, excepto la comparación de los algoritmos. Para hacer una prueba se aplicó un análisis de serie de tiempo usando como base el algoritmo encapsulado en la clase \texttt{LinearRegression}, esta opción  del menú se ve en la figura \ref{fig:menuSeriesDeTiempo}, en el submenú algoritmos base; al elegir esta opción (o cualquier otra) se despliega la vista \texttt{VentanaParametros} de la figura \ref{fig:VentanaParametros} para elegir la configuración de la prueba, y después de oprimir el botón aceptar, aparece una nueva ventana similar a la de la figura \ref{fig:resultadoAplicarAlgoritmo} con una gráfica representando los resultados de la prueba, en el título de esta se encuentra el nombre del algoritmo aplicado, y el error medio absoluto (MAE) que arrojo la prueba.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/resultadoAplicarAlgoritmo.png}
	\caption{gráfica con los resultados de aplicar un algoritmo}
	\label{fig:resultadoAplicarAlgoritmo}
\end{figure}

La gráfica de resultados muestra la serie de tiempo usada para el entrenamiento en azul, y los datos predichos por el algoritmo seleccionado en rojo. El tamaño de la predicción es del tamaño especificado por el parámetro \textit{``Instancias de pruebas''} en la figura \ref{fig:VentanaParametros}, estos datos de pruebas pertenecen a las últimas $n$ instancias del archivo arff elegido. Todo lo demás que no son las instancias de pruebas se usan para entrenar el modelo, y los datos de prueba se usan para comparar la predicción con estos. Tanto los datos de entrenamiento como los datos de pruebas se muestran en azul.
Como los datos son muchos, representarlos todos en una ventana resulta en una gráfica donde los detalles no se aprecian, para ver los detalles se puede acercar la imagen a un segmento específico de la gráfica presionando el botón izquierdo del ratón en una equina superior izquierda, y arrastrando el puntero hasta una esquina inferior derecha formando el cuadro del área a agrandar, tal como se muestra en la figura \ref{fig:haciendoZoom}, al soltar el botón se realiza el acertamiento, el cual muestra solamente el área seleccionada en la ventana, dando como resultado algo similar a la figura \ref{fig:zoom}, Esto permite comparar mejor los resultados del algoritmo.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/haciendoZoom.png}
	\caption{Especificando área a magnificar.}
	\label{fig:haciendoZoom}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/zoom.png}
	\caption{Acercamiento al área especificada.}
	\label{fig:zoom}
\end{figure}

\clearpage
Estos mismos pasos se pueden seguir para aplicar cualquiera de los otros algoritmos individuales, es decir los algoritmos en los menús:  \textit{Series de tiempo $\rightarrow$ aplicar base} (figura \ref{fig:menuSeriesDeTiempo}), \textit{Redes bayesianas $\rightarrow$ aplicar algoritmo de construcción de red} (figura \ref{fig:menuRedesBayesianasAlgoritmo}) y  \textit{Bagging $\rightarrow$ aplicar algoritmo base} (figura \ref{fig:menuBagging}); las opciones que tienen un resultado diferente a estas son las opciones de comparación de algoritmos, es decir las opciones \textit{Series de tiempo $\rightarrow$ comparar algoritmos base}, \textit{Redes bayesianas $\rightarrow$ comparar algoritmos de construcción} y \textit{Bagging $\rightarrow$ comparar algoritmos base del Bagging}. Estas se inician similar, se oprime la opción, aparece la ventana para especificar los parámetros, y al dar aceptar comienza a compararlos, esta vez teniendo una salida extra: los resultados de cada uno de los algoritmos y el algoritmo con mejor desempeñó, esta vista se muestra en la figura \ref{fig:resultadosCompararAlgoritmo}.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/resultadosCompararAlgoritmo.png}
	\caption{Resultados de comparación de algoritmos.}
	\label{fig:resultadosCompararAlgoritmo}
\end{figure}

Para esta prueba se compararon los resultados de los algoritmos base de series de tiempo, pero esta ventana de resultados es común para los otras opciones de comparación de algoritmos, en todas se muestra el nombre de la clase que contiene el algoritmo, el error medio absoluto (MAE) que tuvo ese algoritmo, el error cuadrado medio (MSE), la raíz del error cuadrado medio (RMSE),  %poner esto en el marco teorico
 la media del error porcentual absoluto (MAPE) y al final se muestra el algoritmo que mejor se desempeñó (el que tuvo menor error medio absoluto). 
Además de esta salida, también se muestra la gráfica de resultados del algoritmo que tuvo mejor desempeño, esta es la misma gráfica que la de la figura \ref{fig:resultadoAplicarAlgoritmo}.

\subsection{Visualizar estadísticas}
Además de probar los algoritmos con los datos del servidor, la interfaz también ofrece la funcionalidad de visualizar los resultados de las predicciones mientras estaba en funcionamiento el Agente COLDPower, y así ver que tan bien se dan las predicciones en cada timeslot. 
Estas estadísticas son guardadas en archivos por la clase \texttt{Statistics} (véase sección \ref{subsec:claseStatistics}) en una carpeta, y todos estos archivos guardados se pueden abrir de una sola vez con la opción \textit{Abrir carpeta de estadísticas} del menú Archivo. Esta opción abre un \texttt{JFileChooser} similar al de la figura \ref{fig:seleccionArchivo}, pero destinado a elegir una carpeta en vez de un archivo.
Al elegir una carpeta con los archivos arff correspondientes a los resultados, esta carga los archivos, y abre el primero de ellos, graficándolo en la ventana como se muestra en la figura \ref{fig:GraficaEstadisticas}.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/GraficaEstadisticas.png}
	\caption{Gráfica de las estadísticas generadas en el timeslot 385.}
	\label{fig:GraficaEstadisticas}
\end{figure}

Esta gráfica representa las predicciones que se hicieron en el timeslot 385, en este momento el agente solo contaba con los datos de los timeslots anteriores, e hizo una predicción la cual está graficada en color azul, conforme fueron avanzando los timeslots la clase \texttt{Statistics} se encargó de guardar los valores reales de los kilowatts producidos/consumidos, para poder compararlos con la predicción, estos valores reales están graficados en color rojo. La gráfica de color verde representa los resultados hechos por el método de predicción básico anterior, un promedio ponderado de los valores para las mismas horas, donde los valores anteriores tienen menos peso que los recientes, esta gráfica ayuda a comparar que tanto se mejoro en la predicción, podemos ver que la gráfica de la predicción con los métodos de regresión (la azul) es mucho mejor que la del método anterior (la verde); y si se diese el caso en el que las dos gráficas son muy parecidas, podemos compararlas por su error medio absoluto que aparece en el título de la ventana, en la que el primer valor (Regresión: 3109.324) es el error medio absoluto de la predicción hecha con los nuevos métodos, y el segundo valor (Exponential weighted 9366.662) corresponde al error medio absoluto de la predicción hecha con el método anterior.

Para moverse entre las predicciones de los timeslots podemos oprimir el menú \textit{Estadísticas $\rightarrow$ Siguiente timeslot} o en \textit{Estadísticas $\rightarrow$ Anterior timeslot} tal como se ve en la figura \ref{fig:menuEstadisticas}, o bien con las teclas de dirección izquierda o arriba, para ir al timeslot anterior, o las teclas derecha o arriba, para ir al siguiente timeslot.
El menú \textit{Estadísticas} también tiene la opción \textit{Calcular error global}, el cual sirve para obtener una métrica de error no solo del archivo actual, si no de todos los archivos que se encuentran en la carpeta, al seleccionarla aparecen los resultados en la barra de título, tal como en la imagen \ref{fig:GraficaEstadisticas}, pero con la cadena ``global:'' precediendo los resultados.


\section{Pruebas del Agente COLDPower con el servidor de simulación PowerTAC} \label{sec:pruebasBroker}

Las pruebas que se hicieron anteriormente fueron con los datos del servidor directamente, sin que hubiera los \textit{ruidos} generados por un juego de competencia real, donde las acciones de los otros agentes repercuten en los resultados de las predicciones, y en donde las predicciones del clima dadas por el servidor no son exactas (ver sección \ref{subsec:prediccionClimaProduccion}) y como los algoritmos para predecir la producción eólica y solar son de clasificación, dependen de saber las variables del clima para calcular la energía producida estimada (por lo que no sería predicción, si no clasificación), por lo que estas pruebas diferirían mucho de los resultados de las predicciones que se obtendrían en un juego real, y por esta razón fue necesario implementar mecanismos para medir el desempeño en este ambiente de ejecución real, que es una competencia.

Para poder hacer estas pruebas con la API ya integrada al Agente, se necesitó guardar en archivos los resultados de las predicciones en cada timeslot, ya que en cada uno se necesitan las predicciones de los siguientes 24 timeslots, y cada que se avanza un lugar la predicción para los próximos 23 timeslots cambia. Lo que se hizo fue añadir una clase que se encargara únicamente de recolectar estos datos y guardarlos para después compararlos con ayuda de la interfaz gráfica, esta clase se le llamo \texttt{Statistics}.

\subsection{La clase \texttt{Statistics}} \label{subsec:claseStatistics}
Esta clase se encuentra en el paquete org.powertac.coldbroker.tools.forecast del Agente, y es usada por la clase \texttt{CustomersForecastDataView} para guardar las predicciones hechas por los métodos de predicción cada timeslot.
El diagrama de la figura \ref{fig:StatisticsUML} muestra una representación en UML %poner en el marco teorico?
de la clase \texttt{Statistics}.

\begin{wrapfigure}{r}{7cm}
	\includegraphics[width=7cm]{img/StatisticsUML.png}
	\caption{Diagrama UML de la clase \texttt{Statistics}}
	\label{fig:StatisticsUML}
\end{wrapfigure}

El objeto \texttt{forecasts} es un Hash map que contiene las predicciones de todos los timeslots, la llave es un entero que representa el id del timeslot origen (el timeslot donde se hicieron las predicciones), y los valores son objetos de la clase \texttt{Instances}, los cuales contienen las 24 predicciones hechas en el timeslot origen. 
El atributo \texttt{name} es el nombre que se le da al principio al objeto mediante su constructor, este se usará como sufijo de los nombres de los archivos que va a guardar, así pues, si el nombre es ``Consumo'', los archivos generados por ese objeto serán de nombre ``ForecastConsumoX.arff'', donde X es el id del timeslot donde las predicciones se hicieron (ejemplo figura \ref{fig:ArchivoEstadisticas}).
El atributo \texttt{turnOn} permite deshabilitar el objeto de manera que no guarde ningún archivo y no consuma memoria, debido a que esta clase es solo para fines de depuración, pues solo sirve para generar archivos con los cuales se analizará el desempeño de los algoritmos de predicción con la interfaz gráfica, en un futuro se querrá dejar de generar estos archivos, por lo que resulta muy conveniente solo llamar al método \texttt{setTurnOn} y pasarle \texttt{false} como parámetro, en lugar de quitar todos los usos de las variables de tipo \texttt{Statistics}.

El método \texttt{addForecast} agrega una predicción hecha en el timeslot especificado por el parámetro \textit{currentTs}, este busca el objeto \texttt{Instances} en donde se están guardando las predicciones para ese timeslot, e inserta los datos \textit{timeslot, kwBn} y \textit{kwWV}, especificados en sus parámetros, el parámetro \textit{timeslot} es el timeslot el cual se está prediciendo, y los parámetros \textit{kwBn} y \textit{kwWV} son las predicciones para dicho timeslot usando los métodos de regresión nuevos y el método viejo respectivamente. El parámetro \textit{kwBn} se llama así ya que originalmente la clase se hizo para probar el desempeño de las redes bayesianas, (BayesNets), pero después se reutilizó esta clase para probar los demás métodos.

El método \texttt{addActualKw} sirve para agregar los datos reales, es decir, los kilowatts que se produjeron o consumieron en un timeslot, ambos valores (los kilowats y el timeslot) son especificados en los parámetros de la función, y esta se encarga de buscar los objetos \texttt{Instances} que tienen una predicción para ese timeslot, y les asigna el valor real para después poder compararlo con las predicciones tal como se muestra en la figura \ref{fig:GraficaEstadisticas}, cuando se juntan las 24 predicciones con los 24 valores reales (24 timeslots después de que se hicieron las predicciones) la función guarda el objeto \texttt{Instances} en un archivo, y este archivo es el que se usa para generar las gráficas como la de la figura \ref{fig:GraficaEstadisticas}. Un ejemplo de archivo generado por la clase \texttt{Statistics} se muestra en la figura \ref{fig:ArchivoEstadisticas}, de hecho este archivo es el que se usó para generar la gráfica \ref{fig:GraficaEstadisticas}, este representa la predicción y los valores reales del balance general (la producción menos el consumo) para los timeslots 386 al 409 en un juego, también se guardaron datos de producción, datos de consumo, y datos de distintos power types para poder ver el desempeño de los algoritmos para sus específicos power types, incluso datos del clima.

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{img/ArchivoEstadisticas.png}
	\caption{Archivo arff de las estadísticas generadas en el timeslot 385.}
	\label{fig:ArchivoEstadisticas}
\end{figure}
%Mostrar que la predicción depende de la predicción del clima
\subsection{Pruebas de predicción del clima y su influencia en producción} \label{subsec:prediccionClimaProduccion}

Como el servidor PowerTAC le envía al Agente mensajes con la predicción del clima, las cuales fueron predicciones reales por un servicio meteorológico real (y los datos del clima usados en el servidor también son reales, correspondientes a estas predicciones) no valía la pena predecir uno mismo las variables del clima, así que se opto por tomar las que envía el servidor, no obstante también se le hicieron pruebas a estas predicciones para cuantificar su precisión, en la figura \ref{fig:prediccionViento1310} se muestran las predicciones de velocidad del viento enviadas por el servidor en el timeslot 1310, podemos observar que estas predicciones no fueron muy acertadas en ese timeslot (la gráfica roja son los valores reales y la verde los valores predichos) , y como el algoritmo usado para calcular la producción de los clientes de power type wind production fue una red bayesiana (luego cambiado por el algoritmo Bagging, véase \ref{subsec:comparacionBaggingRedB}), el proceso que realiza es una clasificación, por lo que necesita contar con las variables del clima del timeslot que desea calcular y para esto ocupa la predicción del servidor, esto hace que si el reporte del clima enviado es malo, la predicción de los kilowatts producidos sea mala. Como ejemplo a esto, en la figura \ref{fig:produccionViento1310} vemos la predicción de los kilowatts producidos por clientes de power type wind production (la gráfica roja son los valores reales y la azul los valores predichos), hecha en el mismo timeslot 1310, y podemos ver que al igual que la predicción de la velocidad del viento, es bastante errada, y de la misma forma ya que la predicción de velocidad del viento fue menor que los valores reales, y en el caso de la predicción de producción eólica también fue menor que la predicción real.

En contraste a esto, la predicción de la velocidad del viento generada en el timeslot 1320 que se muestra en la figura \ref{fig:prediccionViento1320} fue bastante buena, esto hizo que la predicción de la producción eólica que se generó en dicho timeslot, fuera mejor que la que se generó en el timeslot 1310. En la figura \ref{fig:produccionViento1320} se puede ver la gráfica de las predicciones generadas en el timeslot 1320, podemos ver que su error medio absoluto fue de 265.633, a diferencia del generado en el timeslot 1310 que tuvo un error medio absoluto de 2541.622.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/prediccionViento1310.png}
	\caption{Predicción de velocidad del viento en el timeslot 1310}
	\label{fig:prediccionViento1310}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/produccionViento1310.png}
	\caption{Predicciones para la producción de power type wind production en el timeslot 1310}
	\label{fig:produccionViento1310}
\end{figure}


\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/prediccionViento1320.png}
	\caption{Predicción de velocidad del viento en el timeslot 1320.}
	\label{fig:prediccionViento1320}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/produccionViento1320.png}
	\caption{Predicciones para la producción de power type wind production en el timeslot 1320.}
	\label{fig:produccionViento1320}
\end{figure}
\clearpage
%con 3 agentes, sin los 3 agentes, etc
\subsection{Pruebas contra el default broker y los agentes Maxon y AgentUDE} \label{subsection:pruebasDefaultBrokerMaxonYUDE}

Las primeros pruebas que se hicieron con el agente COLDPower corriendo con la API integrada, fueron únicamente contra el default broker, esto daba muy buenos resultados en las predicciones puesto que no había interferencias de los otros agentes, y el default broker no causa  mucho impacto en el juego contra el agente COLDPower, en la figura \ref{fig:errorGlobalInterrumpible1agente} podemos ver las gráficas de predicciones del consumo interrumpible (se eligieron estas para este ejemplo porque son las mas estables y se nota mas la interferencia de los otros agentes) mientras jugaba el agente COLDPower solo contra el default broker, estas predicciones fueron buenas en comparación con las hechas en juegos contra los agentes Maxon y AgentUDE, en donde estos ganan y pierden clientes durante el juego, haciendo que estos clientes se suscriban o cancelen a las tarifas del agente COLDPower, lo cual hace que la predicción justo antes que ocurra uno de estos cambios sea mala.

\begin{figure}[h]
	\centering
	\includegraphics[width=11cm]{img/errorGlobalInterrumpible1agente.png}
	\caption{Predicción de power type interrumpible en juego contra el default broker.}
	\label{fig:errorGlobalInterrumpible1agente}
\end{figure}

En la figura \ref{fig:errorGlobalInterrumpible3agentes} vemos como fue la predicción para el timeslot 396 (gráfica en azul, datos reales en rojo) mientras jugaban los tres agentes (AgentUDE, Maxon y COLDPower), la cual dio 0 para los próximos 24 timeslots ya que en ese momento no había clientes, pero a partir del timeslot 397 empezó a tener clientes. 
La población por cada timeslot para los power type de consumo y consumo interrumpible se guardo en el el archivo \texttt{Poblacion.txt} para después poder hacer análisis con estos datos y las predicciones, la figura \ref{fig:poblaciontxt} muestra el archivo en el cual podemos ver que en el timeslot 396 no había clientes y a partir del 397 empezaron a llegar.
También podemos ver en este archivo que la predicción para los siguientes 24 timeslots fue 0 en el timeslot 396 y 396, esto lo dice después de las lineas que dicen ``Se lleno buffer'', ya que esta predicción se guarda en un buffer, y se puede ver que a partir del timeslot 397 esta predicción ya no es 0, pues ya tiene clientes que consuman energía y la predicción de esta energia consumida por ellos no es 0, aunque es baja, tal como se ve en la figura \ref{fig:interrumpibleTimeslot398}, en esta gráfica se ve la predicción que se hizo cuando el agente había ganado pocos clientes, y el modulo de predicción supone que se mantendrá con esos mismos clientes por los próximos 24 timeslots, por lo cual los valores predichos son bajos, de la misma magnitud de los valores reales del timeslot 399 al 403, pero como en los timeslots 404 y 410 se ganaron mas clientes, los valores reales aumentaron en estos timeslots, haciendo que la predicción hecha en los timeslots 396 y 398 no se parezcan en nada.
En las figuras \ref{fig:interrumpibleTimeslot405} y \ref{fig:interrumpibleTimeslot411} se muestran los cambios en la predicción que provoco el ganar mas clientes en los timeslots 404 y 410, en las predicciones hechas en los timeslots 405 y 411 respectivamente. 
Podemos ver que como en el timeslot 404 gana mas clientes, la predicción hecha en el 405 (figura \ref{fig:interrumpibleTimeslot405}) fue buena hasta el timeslot 409, ya que en el 410 llegaron mas clientes los cuales gastaron mas energía, y la predicción que se hizo fue asumiendo que no llegarían mas. 
A su vez esta predicción mejoro en el timeslot 411 (figura \ref{fig:interrumpibleTimeslot411}) ya que en ese punto contaba con el numero de clientes que se mantuvo en los timeslots siguientes.

\begin{figure}[ht]
	\centering
	\includegraphics[width=11cm]{img/errorGlobalInterrumpible3agentes.png}
	\caption{Predicción de power type interrumpible en juego contra los agentes Maxon y AgentUDE.}
	\label{fig:errorGlobalInterrumpible3agentes}
\end{figure}

Por estas razones el error medio absoluto de todo el juego fue menor cuando solo participo el Agente COLDPower con el default broker (520.98 como se ve en la figura \ref{fig:errorGlobalInterrumpible1agente} en el titulo de la ventana) que cuando participaron también los agentes Maxon y AgentUDE (2179.60 como se ve en la figura \ref{fig:errorGlobalInterrumpible3agentes}).

\begin{figure}[ht]
	\centering
	\includegraphics[width=11.25cm]{img/poblaciontxt.png}
	\caption{Archivo \texttt{Poblacion.txt}.}
	\label{fig:poblaciontxt}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=11cm]{img/interrumpibleTimeslot398.png}
	\caption{Predicción hecha en timeslot 398, cuando tenia pocos clientes.}
	\label{fig:interrumpibleTimeslot398}
\end{figure}

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=17cm]{images/predicciones405y411.png}
%	\caption{Predicciones hechas en los timeslots 405 y 411}
%	\label{fig:predicciones405y411}
%\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{img/interrumpibleTimeslot405.png}
	\caption{Predicciones hechas en el timeslot 405.}
	\label{fig:interrumpibleTimeslot405}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{img/interrumpibleTimeslot411.png}
	\caption{Predicciones hechas en el timeslot 411.}
	\label{fig:interrumpibleTimeslot411}
\end{figure}
